WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

ERROR:absl:Could not load object file for ICP op.
WARNING:tensorflow:From train.py:81: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

W1207 04:19:48.204365 140435988830016 module_wrapper.py:139] From train.py:81: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From train.py:88: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.

W1207 04:19:48.208292 140435988830016 module_wrapper.py:139] From train.py:88: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.

I1207 04:19:48.208476 140435988830016 model.py:68] data_dir: /home/pachipala/vid2depth/data/bike
I1207 04:19:48.208623 140435988830016 model.py:69] learning_rate: 0.0002
I1207 04:19:48.208702 140435988830016 model.py:70] beta1: 0.9
I1207 04:19:48.208739 140435988830016 model.py:71] smooth_weight: 0.05
I1207 04:19:48.208772 140435988830016 model.py:72] ssim_weight: 0.15
I1207 04:19:48.208803 140435988830016 model.py:73] icp_weight: 0.0
I1207 04:19:48.208834 140435988830016 model.py:74] batch_size: 4
I1207 04:19:48.208899 140435988830016 model.py:75] img_height: 128
I1207 04:19:48.208930 140435988830016 model.py:76] img_width: 416
I1207 04:19:48.208960 140435988830016 model.py:77] seq_length: 3
I1207 04:19:48.208990 140435988830016 model.py:78] legacy_mode: False
I1207 04:19:48.209214 140435988830016 reader.py:181] data_dir: /home/pachipala/vid2depth/data/bike
WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/reader.py:182: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.

W1207 04:19:48.209311 140435988830016 module_wrapper.py:139] From /home/pachipala/models/research/vid2depth/reader.py:182: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.

WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/reader.py:53: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.
W1207 04:19:49.502374 140435988830016 deprecation.py:323] From /home/pachipala/models/research/vid2depth/reader.py:53: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.
WARNING:tensorflow:From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.
W1207 04:19:50.102597 140435988830016 deprecation.py:323] From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.
WARNING:tensorflow:From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.
W1207 04:19:50.103368 140435988830016 deprecation.py:323] From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.
WARNING:tensorflow:From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W1207 04:19:50.104649 140435988830016 deprecation.py:323] From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
WARNING:tensorflow:From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W1207 04:19:50.105477 140435988830016 deprecation.py:323] From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/reader.py:56: WholeFileReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.map(tf.read_file)`.
W1207 04:19:50.656678 140435988830016 deprecation.py:323] From /home/pachipala/models/research/vid2depth/reader.py:56: WholeFileReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.map(tf.read_file)`.
WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/reader.py:61: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.
W1207 04:19:50.658482 140435988830016 deprecation.py:323] From /home/pachipala/models/research/vid2depth/reader.py:61: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.
WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/reader.py:66: The name tf.decode_csv is deprecated. Please use tf.io.decode_csv instead.

W1207 04:19:50.659472 140435988830016 module_wrapper.py:139] From /home/pachipala/models/research/vid2depth/reader.py:66: The name tf.decode_csv is deprecated. Please use tf.io.decode_csv instead.

WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/reader.py:121: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W1207 04:19:50.666245 140435988830016 module_wrapper.py:139] From /home/pachipala/models/research/vid2depth/reader.py:121: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/reader.py:151: The name tf.image.resize_area is deprecated. Please use tf.compat.v1.image.resize_area instead.

W1207 04:19:50.708120 140435988830016 module_wrapper.py:139] From /home/pachipala/models/research/vid2depth/reader.py:151: The name tf.image.resize_area is deprecated. Please use tf.compat.v1.image.resize_area instead.

WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/reader.py:86: The name tf.matrix_inverse is deprecated. Please use tf.linalg.inv instead.

W1207 04:19:50.833657 140435988830016 module_wrapper.py:139] From /home/pachipala/models/research/vid2depth/reader.py:86: The name tf.matrix_inverse is deprecated. Please use tf.linalg.inv instead.

WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/reader.py:95: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.
W1207 04:19:50.834306 140435988830016 deprecation.py:323] From /home/pachipala/models/research/vid2depth/reader.py:95: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.
I1207 04:19:50.841874 140435988830016 reader.py:96] image_stack: Tensor("data_loading/batching/shuffle_batch:0", shape=(4, 128, 416, 9), dtype=float32)
WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/nets.py:81: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1207 04:19:50.842058 140435988830016 module_wrapper.py:139] From /home/pachipala/models/research/vid2depth/nets.py:81: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
W1207 04:19:50.842980 140435988830016 deprecation.py:323] From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/nets.py:207: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.

W1207 04:19:51.561712 140435988830016 module_wrapper.py:139] From /home/pachipala/models/research/vid2depth/nets.py:207: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.

WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/nets.py:172: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.

W1207 04:19:51.807591 140435988830016 module_wrapper.py:139] From /home/pachipala/models/research/vid2depth/nets.py:172: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.

WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/model.py:127: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.

W1207 04:19:52.056748 140435988830016 module_wrapper.py:139] From /home/pachipala/models/research/vid2depth/model.py:127: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.

I1207 04:19:53.056479 140435988830016 model.py:128] disp: {0: [<tf.Tensor 'depth_prediction/depth_net/add_3:0' shape=(4, 128, 416, 1) dtype=float32>, <tf.Tensor 'depth_prediction/depth_net/add_2:0' shape=(4, 64, 208, 1) dtype=float32>, <tf.Tensor 'depth_prediction/depth_net/add_1:0' shape=(4, 32, 104, 1) dtype=float32>, <tf.Tensor 'depth_prediction/depth_net/add:0' shape=(4, 16, 52, 1) dtype=float32>], 1: [<tf.Tensor 'depth_prediction/depth_net_1/add_3:0' shape=(4, 128, 416, 1) dtype=float32>, <tf.Tensor 'depth_prediction/depth_net_1/add_2:0' shape=(4, 64, 208, 1) dtype=float32>, <tf.Tensor 'depth_prediction/depth_net_1/add_1:0' shape=(4, 32, 104, 1) dtype=float32>, <tf.Tensor 'depth_prediction/depth_net_1/add:0' shape=(4, 16, 52, 1) dtype=float32>], 2: [<tf.Tensor 'depth_prediction/depth_net_2/add_3:0' shape=(4, 128, 416, 1) dtype=float32>, <tf.Tensor 'depth_prediction/depth_net_2/add_2:0' shape=(4, 64, 208, 1) dtype=float32>, <tf.Tensor 'depth_prediction/depth_net_2/add_1:0' shape=(4, 32, 104, 1) dtype=float32>, <tf.Tensor 'depth_prediction/depth_net_2/add:0' shape=(4, 16, 52, 1) dtype=float32>]}
WARNING:tensorflow:From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
W1207 04:19:53.225701 140435988830016 deprecation.py:506] From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/project.py:217: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W1207 04:19:53.267238 140435988830016 deprecation.py:323] From /home/pachipala/models/research/vid2depth/project.py:217: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/model.py:271: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W1207 04:19:56.913547 140435988830016 module_wrapper.py:139] From /home/pachipala/models/research/vid2depth/model.py:271: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W1207 04:19:57.126230 140435988830016 deprecation.py:323] From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/model.py:274: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

W1207 04:20:08.153923 140435988830016 module_wrapper.py:139] From /home/pachipala/models/research/vid2depth/model.py:274: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/model.py:278: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W1207 04:20:08.155596 140435988830016 module_wrapper.py:139] From /home/pachipala/models/research/vid2depth/model.py:278: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/model.py:289: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W1207 04:20:08.159027 140435988830016 module_wrapper.py:139] From /home/pachipala/models/research/vid2depth/model.py:289: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/model.py:298: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

W1207 04:20:08.191059 140435988830016 module_wrapper.py:139] From /home/pachipala/models/research/vid2depth/model.py:298: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

I1207 04:20:08.311558 140435988830016 util.py:72] Model Parameters:
WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/util.py:94: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1207 04:20:08.311712 140435988830016 module_wrapper.py:139] From /home/pachipala/models/research/vid2depth/util.py:94: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From /home/pachipala/models/research/vid2depth/util.py:96: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W1207 04:20:08.311822 140435988830016 module_wrapper.py:139] From /home/pachipala/models/research/vid2depth/util.py:96: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

I1207 04:20:08.312841 140435988830016 util.py:77] depth_prediction/depth_net/cnv1/BatchNorm/beta (32,): 32
I1207 04:20:08.312960 140435988830016 util.py:77] depth_prediction/depth_net/cnv1/BatchNorm/moving_mean (32,): 32
I1207 04:20:08.313037 140435988830016 util.py:77] depth_prediction/depth_net/cnv1/BatchNorm/moving_variance (32,): 32
I1207 04:20:08.313112 140435988830016 util.py:77] depth_prediction/depth_net/cnv1/weights (7, 7, 3, 32): 4,704
I1207 04:20:08.313185 140435988830016 util.py:77] depth_prediction/depth_net/cnv1b/BatchNorm/beta (32,): 32
I1207 04:20:08.313250 140435988830016 util.py:77] depth_prediction/depth_net/cnv1b/BatchNorm/moving_mean (32,): 32
I1207 04:20:08.313333 140435988830016 util.py:77] depth_prediction/depth_net/cnv1b/BatchNorm/moving_variance (32,): 32
I1207 04:20:08.313402 140435988830016 util.py:77] depth_prediction/depth_net/cnv1b/weights (7, 7, 32, 32): 50,176
I1207 04:20:08.313473 140435988830016 util.py:77] depth_prediction/depth_net/cnv2/BatchNorm/beta (64,): 64
I1207 04:20:08.313539 140435988830016 util.py:77] depth_prediction/depth_net/cnv2/BatchNorm/moving_mean (64,): 64
I1207 04:20:08.313615 140435988830016 util.py:77] depth_prediction/depth_net/cnv2/BatchNorm/moving_variance (64,): 64
I1207 04:20:08.313685 140435988830016 util.py:77] depth_prediction/depth_net/cnv2/weights (5, 5, 32, 64): 51,200
I1207 04:20:08.313753 140435988830016 util.py:77] depth_prediction/depth_net/cnv2b/BatchNorm/beta (64,): 64
I1207 04:20:08.313818 140435988830016 util.py:77] depth_prediction/depth_net/cnv2b/BatchNorm/moving_mean (64,): 64
I1207 04:20:08.313880 140435988830016 util.py:77] depth_prediction/depth_net/cnv2b/BatchNorm/moving_variance (64,): 64
I1207 04:20:08.313946 140435988830016 util.py:77] depth_prediction/depth_net/cnv2b/weights (5, 5, 64, 64): 102,400
I1207 04:20:08.314013 140435988830016 util.py:77] depth_prediction/depth_net/cnv3/BatchNorm/beta (128,): 128
I1207 04:20:08.314078 140435988830016 util.py:77] depth_prediction/depth_net/cnv3/BatchNorm/moving_mean (128,): 128
I1207 04:20:08.314142 140435988830016 util.py:77] depth_prediction/depth_net/cnv3/BatchNorm/moving_variance (128,): 128
I1207 04:20:08.314208 140435988830016 util.py:77] depth_prediction/depth_net/cnv3/weights (3, 3, 64, 128): 73,728
I1207 04:20:08.314274 140435988830016 util.py:77] depth_prediction/depth_net/cnv3b/BatchNorm/beta (128,): 128
I1207 04:20:08.314359 140435988830016 util.py:77] depth_prediction/depth_net/cnv3b/BatchNorm/moving_mean (128,): 128
I1207 04:20:08.314419 140435988830016 util.py:77] depth_prediction/depth_net/cnv3b/BatchNorm/moving_variance (128,): 128
I1207 04:20:08.314482 140435988830016 util.py:77] depth_prediction/depth_net/cnv3b/weights (3, 3, 128, 128): 147,456
I1207 04:20:08.314544 140435988830016 util.py:77] depth_prediction/depth_net/cnv4/BatchNorm/beta (256,): 256
I1207 04:20:08.314611 140435988830016 util.py:77] depth_prediction/depth_net/cnv4/BatchNorm/moving_mean (256,): 256
I1207 04:20:08.314671 140435988830016 util.py:77] depth_prediction/depth_net/cnv4/BatchNorm/moving_variance (256,): 256
I1207 04:20:08.314732 140435988830016 util.py:77] depth_prediction/depth_net/cnv4/weights (3, 3, 128, 256): 294,912
I1207 04:20:08.314795 140435988830016 util.py:77] depth_prediction/depth_net/cnv4b/BatchNorm/beta (256,): 256
I1207 04:20:08.314854 140435988830016 util.py:77] depth_prediction/depth_net/cnv4b/BatchNorm/moving_mean (256,): 256
I1207 04:20:08.314911 140435988830016 util.py:77] depth_prediction/depth_net/cnv4b/BatchNorm/moving_variance (256,): 256
I1207 04:20:08.314972 140435988830016 util.py:77] depth_prediction/depth_net/cnv4b/weights (3, 3, 256, 256): 589,824
I1207 04:20:08.315034 140435988830016 util.py:77] depth_prediction/depth_net/cnv5/BatchNorm/beta (512,): 512
I1207 04:20:08.315094 140435988830016 util.py:77] depth_prediction/depth_net/cnv5/BatchNorm/moving_mean (512,): 512
I1207 04:20:08.315153 140435988830016 util.py:77] depth_prediction/depth_net/cnv5/BatchNorm/moving_variance (512,): 512
I1207 04:20:08.315215 140435988830016 util.py:77] depth_prediction/depth_net/cnv5/weights (3, 3, 256, 512): 1,179,648
I1207 04:20:08.315276 140435988830016 util.py:77] depth_prediction/depth_net/cnv5b/BatchNorm/beta (512,): 512
I1207 04:20:08.315334 140435988830016 util.py:77] depth_prediction/depth_net/cnv5b/BatchNorm/moving_mean (512,): 512
I1207 04:20:08.315392 140435988830016 util.py:77] depth_prediction/depth_net/cnv5b/BatchNorm/moving_variance (512,): 512
I1207 04:20:08.315473 140435988830016 util.py:77] depth_prediction/depth_net/cnv5b/weights (3, 3, 512, 512): 2,359,296
I1207 04:20:08.315538 140435988830016 util.py:77] depth_prediction/depth_net/cnv6/BatchNorm/beta (512,): 512
I1207 04:20:08.315609 140435988830016 util.py:77] depth_prediction/depth_net/cnv6/BatchNorm/moving_mean (512,): 512
I1207 04:20:08.315671 140435988830016 util.py:77] depth_prediction/depth_net/cnv6/BatchNorm/moving_variance (512,): 512
I1207 04:20:08.315736 140435988830016 util.py:77] depth_prediction/depth_net/cnv6/weights (3, 3, 512, 512): 2,359,296
I1207 04:20:08.315802 140435988830016 util.py:77] depth_prediction/depth_net/cnv6b/BatchNorm/beta (512,): 512
I1207 04:20:08.315881 140435988830016 util.py:77] depth_prediction/depth_net/cnv6b/BatchNorm/moving_mean (512,): 512
I1207 04:20:08.315944 140435988830016 util.py:77] depth_prediction/depth_net/cnv6b/BatchNorm/moving_variance (512,): 512
I1207 04:20:08.316029 140435988830016 util.py:77] depth_prediction/depth_net/cnv6b/weights (3, 3, 512, 512): 2,359,296
I1207 04:20:08.316111 140435988830016 util.py:77] depth_prediction/depth_net/cnv7/BatchNorm/beta (512,): 512
I1207 04:20:08.316173 140435988830016 util.py:77] depth_prediction/depth_net/cnv7/BatchNorm/moving_mean (512,): 512
I1207 04:20:08.316234 140435988830016 util.py:77] depth_prediction/depth_net/cnv7/BatchNorm/moving_variance (512,): 512
I1207 04:20:08.316299 140435988830016 util.py:77] depth_prediction/depth_net/cnv7/weights (3, 3, 512, 512): 2,359,296
I1207 04:20:08.316364 140435988830016 util.py:77] depth_prediction/depth_net/cnv7b/BatchNorm/beta (512,): 512
I1207 04:20:08.316425 140435988830016 util.py:77] depth_prediction/depth_net/cnv7b/BatchNorm/moving_mean (512,): 512
I1207 04:20:08.316486 140435988830016 util.py:77] depth_prediction/depth_net/cnv7b/BatchNorm/moving_variance (512,): 512
I1207 04:20:08.316551 140435988830016 util.py:77] depth_prediction/depth_net/cnv7b/weights (3, 3, 512, 512): 2,359,296
I1207 04:20:08.316624 140435988830016 util.py:77] depth_prediction/depth_net/disp1/biases (1,): 1
I1207 04:20:08.316697 140435988830016 util.py:77] depth_prediction/depth_net/disp1/weights (3, 3, 16, 1): 144
I1207 04:20:08.316764 140435988830016 util.py:77] depth_prediction/depth_net/disp2/biases (1,): 1
I1207 04:20:08.316828 140435988830016 util.py:77] depth_prediction/depth_net/disp2/weights (3, 3, 32, 1): 288
I1207 04:20:08.316906 140435988830016 util.py:77] depth_prediction/depth_net/disp3/biases (1,): 1
I1207 04:20:08.316965 140435988830016 util.py:77] depth_prediction/depth_net/disp3/weights (3, 3, 64, 1): 576
I1207 04:20:08.317026 140435988830016 util.py:77] depth_prediction/depth_net/disp4/biases (1,): 1
I1207 04:20:08.317090 140435988830016 util.py:77] depth_prediction/depth_net/disp4/weights (3, 3, 128, 1): 1,152
I1207 04:20:08.317152 140435988830016 util.py:77] depth_prediction/depth_net/icnv1/BatchNorm/beta (16,): 16
I1207 04:20:08.317210 140435988830016 util.py:77] depth_prediction/depth_net/icnv1/BatchNorm/moving_mean (16,): 16
I1207 04:20:08.317267 140435988830016 util.py:77] depth_prediction/depth_net/icnv1/BatchNorm/moving_variance (16,): 16
I1207 04:20:08.317327 140435988830016 util.py:77] depth_prediction/depth_net/icnv1/weights (3, 3, 17, 16): 2,448
I1207 04:20:08.317388 140435988830016 util.py:77] depth_prediction/depth_net/icnv2/BatchNorm/beta (32,): 32
I1207 04:20:08.317446 140435988830016 util.py:77] depth_prediction/depth_net/icnv2/BatchNorm/moving_mean (32,): 32
I1207 04:20:08.317523 140435988830016 util.py:77] depth_prediction/depth_net/icnv2/BatchNorm/moving_variance (32,): 32
I1207 04:20:08.317609 140435988830016 util.py:77] depth_prediction/depth_net/icnv2/weights (3, 3, 65, 32): 18,720
I1207 04:20:08.317678 140435988830016 util.py:77] depth_prediction/depth_net/icnv3/BatchNorm/beta (64,): 64
I1207 04:20:08.317740 140435988830016 util.py:77] depth_prediction/depth_net/icnv3/BatchNorm/moving_mean (64,): 64
I1207 04:20:08.317801 140435988830016 util.py:77] depth_prediction/depth_net/icnv3/BatchNorm/moving_variance (64,): 64
I1207 04:20:08.317865 140435988830016 util.py:77] depth_prediction/depth_net/icnv3/weights (3, 3, 129, 64): 74,304
I1207 04:20:08.317931 140435988830016 util.py:77] depth_prediction/depth_net/icnv4/BatchNorm/beta (128,): 128
I1207 04:20:08.317992 140435988830016 util.py:77] depth_prediction/depth_net/icnv4/BatchNorm/moving_mean (128,): 128
I1207 04:20:08.318053 140435988830016 util.py:77] depth_prediction/depth_net/icnv4/BatchNorm/moving_variance (128,): 128
I1207 04:20:08.318119 140435988830016 util.py:77] depth_prediction/depth_net/icnv4/weights (3, 3, 256, 128): 294,912
I1207 04:20:08.318184 140435988830016 util.py:77] depth_prediction/depth_net/icnv5/BatchNorm/beta (256,): 256
I1207 04:20:08.318245 140435988830016 util.py:77] depth_prediction/depth_net/icnv5/BatchNorm/moving_mean (256,): 256
I1207 04:20:08.318306 140435988830016 util.py:77] depth_prediction/depth_net/icnv5/BatchNorm/moving_variance (256,): 256
I1207 04:20:08.318371 140435988830016 util.py:77] depth_prediction/depth_net/icnv5/weights (3, 3, 512, 256): 1,179,648
I1207 04:20:08.318436 140435988830016 util.py:77] depth_prediction/depth_net/icnv6/BatchNorm/beta (512,): 512
I1207 04:20:08.318497 140435988830016 util.py:77] depth_prediction/depth_net/icnv6/BatchNorm/moving_mean (512,): 512
I1207 04:20:08.318559 140435988830016 util.py:77] depth_prediction/depth_net/icnv6/BatchNorm/moving_variance (512,): 512
I1207 04:20:08.318632 140435988830016 util.py:77] depth_prediction/depth_net/icnv6/weights (3, 3, 1024, 512): 4,718,592
I1207 04:20:08.318699 140435988830016 util.py:77] depth_prediction/depth_net/icnv7/BatchNorm/beta (512,): 512
I1207 04:20:08.318773 140435988830016 util.py:77] depth_prediction/depth_net/icnv7/BatchNorm/moving_mean (512,): 512
I1207 04:20:08.318837 140435988830016 util.py:77] depth_prediction/depth_net/icnv7/BatchNorm/moving_variance (512,): 512
I1207 04:20:08.318925 140435988830016 util.py:77] depth_prediction/depth_net/icnv7/weights (3, 3, 1024, 512): 4,718,592
I1207 04:20:08.318995 140435988830016 util.py:77] depth_prediction/depth_net/upcnv1/BatchNorm/beta (16,): 16
I1207 04:20:08.319075 140435988830016 util.py:77] depth_prediction/depth_net/upcnv1/BatchNorm/moving_mean (16,): 16
I1207 04:20:08.319143 140435988830016 util.py:77] depth_prediction/depth_net/upcnv1/BatchNorm/moving_variance (16,): 16
I1207 04:20:08.319211 140435988830016 util.py:77] depth_prediction/depth_net/upcnv1/weights (3, 3, 16, 32): 4,608
I1207 04:20:08.319281 140435988830016 util.py:77] depth_prediction/depth_net/upcnv2/BatchNorm/beta (32,): 32
I1207 04:20:08.319347 140435988830016 util.py:77] depth_prediction/depth_net/upcnv2/BatchNorm/moving_mean (32,): 32
I1207 04:20:08.319411 140435988830016 util.py:77] depth_prediction/depth_net/upcnv2/BatchNorm/moving_variance (32,): 32
I1207 04:20:08.319480 140435988830016 util.py:77] depth_prediction/depth_net/upcnv2/weights (3, 3, 32, 64): 18,432
I1207 04:20:08.319550 140435988830016 util.py:77] depth_prediction/depth_net/upcnv3/BatchNorm/beta (64,): 64
I1207 04:20:08.319626 140435988830016 util.py:77] depth_prediction/depth_net/upcnv3/BatchNorm/moving_mean (64,): 64
I1207 04:20:08.319692 140435988830016 util.py:77] depth_prediction/depth_net/upcnv3/BatchNorm/moving_variance (64,): 64
I1207 04:20:08.319761 140435988830016 util.py:77] depth_prediction/depth_net/upcnv3/weights (3, 3, 64, 128): 73,728
I1207 04:20:08.319845 140435988830016 util.py:77] depth_prediction/depth_net/upcnv4/BatchNorm/beta (128,): 128
I1207 04:20:08.319916 140435988830016 util.py:77] depth_prediction/depth_net/upcnv4/BatchNorm/moving_mean (128,): 128
I1207 04:20:08.320000 140435988830016 util.py:77] depth_prediction/depth_net/upcnv4/BatchNorm/moving_variance (128,): 128
I1207 04:20:08.320061 140435988830016 util.py:77] depth_prediction/depth_net/upcnv4/weights (3, 3, 128, 256): 294,912
I1207 04:20:08.320127 140435988830016 util.py:77] depth_prediction/depth_net/upcnv5/BatchNorm/beta (256,): 256
I1207 04:20:08.320185 140435988830016 util.py:77] depth_prediction/depth_net/upcnv5/BatchNorm/moving_mean (256,): 256
I1207 04:20:08.320243 140435988830016 util.py:77] depth_prediction/depth_net/upcnv5/BatchNorm/moving_variance (256,): 256
I1207 04:20:08.320304 140435988830016 util.py:77] depth_prediction/depth_net/upcnv5/weights (3, 3, 256, 512): 1,179,648
I1207 04:20:08.320365 140435988830016 util.py:77] depth_prediction/depth_net/upcnv6/BatchNorm/beta (512,): 512
I1207 04:20:08.320423 140435988830016 util.py:77] depth_prediction/depth_net/upcnv6/BatchNorm/moving_mean (512,): 512
I1207 04:20:08.320481 140435988830016 util.py:77] depth_prediction/depth_net/upcnv6/BatchNorm/moving_variance (512,): 512
I1207 04:20:08.320544 140435988830016 util.py:77] depth_prediction/depth_net/upcnv6/weights (3, 3, 512, 512): 2,359,296
I1207 04:20:08.320611 140435988830016 util.py:77] depth_prediction/depth_net/upcnv7/BatchNorm/beta (512,): 512
I1207 04:20:08.320670 140435988830016 util.py:77] depth_prediction/depth_net/upcnv7/BatchNorm/moving_mean (512,): 512
I1207 04:20:08.320728 140435988830016 util.py:77] depth_prediction/depth_net/upcnv7/BatchNorm/moving_variance (512,): 512
I1207 04:20:08.320789 140435988830016 util.py:77] depth_prediction/depth_net/upcnv7/weights (3, 3, 512, 512): 2,359,296
I1207 04:20:08.320851 140435988830016 util.py:77] pose_exp_net/cnv1/BatchNorm/beta (16,): 16
I1207 04:20:08.320930 140435988830016 util.py:77] pose_exp_net/cnv1/BatchNorm/moving_mean (16,): 16
I1207 04:20:08.321002 140435988830016 util.py:77] pose_exp_net/cnv1/BatchNorm/moving_variance (16,): 16
I1207 04:20:08.321069 140435988830016 util.py:77] pose_exp_net/cnv1/weights (7, 7, 9, 16): 7,056
I1207 04:20:08.321134 140435988830016 util.py:77] pose_exp_net/cnv2/BatchNorm/beta (32,): 32
I1207 04:20:08.321203 140435988830016 util.py:77] pose_exp_net/cnv2/BatchNorm/moving_mean (32,): 32
I1207 04:20:08.321273 140435988830016 util.py:77] pose_exp_net/cnv2/BatchNorm/moving_variance (32,): 32
I1207 04:20:08.321336 140435988830016 util.py:77] pose_exp_net/cnv2/weights (5, 5, 16, 32): 12,800
I1207 04:20:08.321400 140435988830016 util.py:77] pose_exp_net/cnv3/BatchNorm/beta (64,): 64
I1207 04:20:08.321477 140435988830016 util.py:77] pose_exp_net/cnv3/BatchNorm/moving_mean (64,): 64
I1207 04:20:08.321547 140435988830016 util.py:77] pose_exp_net/cnv3/BatchNorm/moving_variance (64,): 64
I1207 04:20:08.321621 140435988830016 util.py:77] pose_exp_net/cnv3/weights (3, 3, 32, 64): 18,432
I1207 04:20:08.321685 140435988830016 util.py:77] pose_exp_net/cnv4/BatchNorm/beta (128,): 128
I1207 04:20:08.321774 140435988830016 util.py:77] pose_exp_net/cnv4/BatchNorm/moving_mean (128,): 128
I1207 04:20:08.321848 140435988830016 util.py:77] pose_exp_net/cnv4/BatchNorm/moving_variance (128,): 128
I1207 04:20:08.321915 140435988830016 util.py:77] pose_exp_net/cnv4/weights (3, 3, 64, 128): 73,728
I1207 04:20:08.321983 140435988830016 util.py:77] pose_exp_net/cnv5/BatchNorm/beta (256,): 256
I1207 04:20:08.322055 140435988830016 util.py:77] pose_exp_net/cnv5/BatchNorm/moving_mean (256,): 256
I1207 04:20:08.322130 140435988830016 util.py:77] pose_exp_net/cnv5/BatchNorm/moving_variance (256,): 256
I1207 04:20:08.322198 140435988830016 util.py:77] pose_exp_net/cnv5/weights (3, 3, 128, 256): 294,912
I1207 04:20:08.322265 140435988830016 util.py:77] pose_exp_net/pose/cnv6/BatchNorm/beta (256,): 256
I1207 04:20:08.322336 140435988830016 util.py:77] pose_exp_net/pose/cnv6/BatchNorm/moving_mean (256,): 256
I1207 04:20:08.322407 140435988830016 util.py:77] pose_exp_net/pose/cnv6/BatchNorm/moving_variance (256,): 256
I1207 04:20:08.322473 140435988830016 util.py:77] pose_exp_net/pose/cnv6/weights (3, 3, 256, 256): 589,824
I1207 04:20:08.322538 140435988830016 util.py:77] pose_exp_net/pose/cnv7/BatchNorm/beta (256,): 256
I1207 04:20:08.322619 140435988830016 util.py:77] pose_exp_net/pose/cnv7/BatchNorm/moving_mean (256,): 256
I1207 04:20:08.322702 140435988830016 util.py:77] pose_exp_net/pose/cnv7/BatchNorm/moving_variance (256,): 256
I1207 04:20:08.322765 140435988830016 util.py:77] pose_exp_net/pose/cnv7/weights (3, 3, 256, 256): 589,824
I1207 04:20:08.322826 140435988830016 util.py:77] pose_exp_net/pose/pred/biases (12,): 12
I1207 04:20:08.322887 140435988830016 util.py:77] pose_exp_net/pose/pred/weights (1, 1, 256, 12): 3,072
I1207 04:20:08.322949 140435988830016 util.py:80] Total: 33,203,728
WARNING:tensorflow:From train.py:116: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W1207 04:20:08.323810 140435988830016 module_wrapper.py:139] From train.py:116: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:119: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W1207 04:20:08.426511 140435988830016 deprecation.py:323] From train.py:119: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
WARNING:tensorflow:From train.py:120: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W1207 04:20:10.441066 140435988830016 module_wrapper.py:139] From train.py:120: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

2023-12-07 04:20:10.441532: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2023-12-07 04:20:10.449482: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz
2023-12-07 04:20:10.450422: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ef7e247df0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2023-12-07 04:20:10.450460: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2023-12-07 04:20:10.452844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2023-12-07 04:20:10.911452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-12-07 04:20:10.913358: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ef7cc9f8e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-12-07 04:20:10.913394: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2023-12-07 04:20:10.913642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-12-07 04:20:10.915174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:00:04.0
2023-12-07 04:20:10.919642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2023-12-07 04:20:10.944431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2023-12-07 04:20:10.959801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2023-12-07 04:20:10.999736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2023-12-07 04:20:11.033891: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2023-12-07 04:20:11.048203: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2023-12-07 04:20:11.086713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2023-12-07 04:20:11.086846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-12-07 04:20:11.088480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-12-07 04:20:11.090008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2023-12-07 04:20:11.090058: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2023-12-07 04:20:11.091726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-12-07 04:20:11.091741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2023-12-07 04:20:11.091749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2023-12-07 04:20:11.091874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-12-07 04:20:11.093415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-12-07 04:20:11.094940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14069 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Running local_init_op.
I1207 04:20:14.189334 140435988830016 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1207 04:20:15.101395 140435988830016 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Starting standard services.
I1207 04:20:29.682672 140435988830016 supervisor.py:737] Starting standard services.
INFO:tensorflow:Starting queue runners.
I1207 04:20:30.525897 140435988830016 supervisor.py:743] Starting queue runners.
I1207 04:20:30.529182 140435988830016 train.py:126] Attempting to resume training from /home/pachipala/vid2depth/checkpoints...
I1207 04:20:30.531733 140435988830016 train.py:128] Last checkpoint found: /home/pachipala/vid2depth/checkpoints/model-123868
INFO:tensorflow:Restoring parameters from /home/pachipala/vid2depth/checkpoints/model-123868
I1207 04:20:30.532975 140435988830016 saver.py:1284] Restoring parameters from /home/pachipala/vid2depth/checkpoints/model-123868
2023-12-07 04:20:40.893100: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x55ef960438a0
2023-12-07 04:20:40.893239: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2023-12-07 04:20:41.145227: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
I1207 04:20:42.055791 140435988830016 train.py:132] Training...
2023-12-07 04:21:11.881406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2023-12-07 04:21:11.882502: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
I1207 04:21:43.313747 140435988830016 train.py:160] Epoch: [ 3] [   32/61934] time: 61.26s (61s total) loss: 0.578
I1207 04:22:13.780200 140435988830016 train.py:160] Epoch: [ 3] [  132/61934] time: 30.47s (91s total) loss: 0.585
I1207 04:22:44.823124 140435988830016 train.py:160] Epoch: [ 3] [  232/61934] time: 31.04s (122s total) loss: 0.841
I1207 04:23:16.575266 140435988830016 train.py:160] Epoch: [ 3] [  332/61934] time: 31.75s (154s total) loss: 0.530
I1207 04:23:48.621201 140435988830016 train.py:160] Epoch: [ 3] [  432/61934] time: 32.05s (186s total) loss: 0.875
I1207 04:24:20.363591 140435988830016 train.py:160] Epoch: [ 3] [  532/61934] time: 31.74s (218s total) loss: 0.549
I1207 04:24:52.271326 140435988830016 train.py:160] Epoch: [ 3] [  632/61934] time: 31.91s (250s total) loss: 0.478
I1207 04:25:24.071275 140435988830016 train.py:160] Epoch: [ 3] [  732/61934] time: 31.80s (282s total) loss: 0.727
I1207 04:25:55.975242 140435988830016 train.py:160] Epoch: [ 3] [  832/61934] time: 31.90s (313s total) loss: 0.646
I1207 04:26:27.870978 140435988830016 train.py:160] Epoch: [ 3] [  932/61934] time: 31.90s (345s total) loss: 0.975
I1207 04:26:59.800171 140435988830016 train.py:160] Epoch: [ 3] [ 1032/61934] time: 31.93s (377s total) loss: 0.488
I1207 04:27:31.663717 140435988830016 train.py:160] Epoch: [ 3] [ 1132/61934] time: 31.86s (409s total) loss: 1.592
I1207 04:28:03.582669 140435988830016 train.py:160] Epoch: [ 3] [ 1232/61934] time: 31.92s (441s total) loss: 0.703
I1207 04:28:35.428920 140435988830016 train.py:160] Epoch: [ 3] [ 1332/61934] time: 31.85s (473s total) loss: 1.405
I1207 04:29:07.186291 140435988830016 train.py:160] Epoch: [ 3] [ 1432/61934] time: 31.76s (505s total) loss: 0.747
I1207 04:29:39.029788 140435988830016 train.py:160] Epoch: [ 3] [ 1532/61934] time: 31.84s (536s total) loss: 1.060
I1207 04:30:10.881553 140435988830016 train.py:160] Epoch: [ 3] [ 1632/61934] time: 31.85s (568s total) loss: 0.700
I1207 04:30:42.728866 140435988830016 train.py:160] Epoch: [ 3] [ 1732/61934] time: 31.85s (600s total) loss: 0.611
I1207 04:31:14.708462 140435988830016 train.py:160] Epoch: [ 3] [ 1832/61934] time: 31.98s (632s total) loss: 0.545
I1207 04:31:46.678540 140435988830016 train.py:160] Epoch: [ 3] [ 1932/61934] time: 31.97s (664s total) loss: 0.629
I1207 04:32:18.632343 140435988830016 train.py:160] Epoch: [ 3] [ 2032/61934] time: 31.95s (696s total) loss: 0.934
I1207 04:32:50.657925 140435988830016 train.py:160] Epoch: [ 3] [ 2132/61934] time: 32.03s (728s total) loss: 0.697
I1207 04:33:22.532411 140435988830016 train.py:160] Epoch: [ 3] [ 2232/61934] time: 31.87s (760s total) loss: 0.744
I1207 04:33:54.301269 140435988830016 train.py:160] Epoch: [ 3] [ 2332/61934] time: 31.77s (792s total) loss: 0.852
I1207 04:34:26.021915 140435988830016 train.py:160] Epoch: [ 3] [ 2432/61934] time: 31.72s (823s total) loss: 0.635
I1207 04:34:57.516763 140435988830016 train.py:160] Epoch: [ 3] [ 2532/61934] time: 31.49s (855s total) loss: 0.695
I1207 04:35:29.138653 140435988830016 train.py:160] Epoch: [ 3] [ 2632/61934] time: 31.62s (887s total) loss: 0.732
I1207 04:36:00.755718 140435988830016 train.py:160] Epoch: [ 3] [ 2732/61934] time: 31.62s (918s total) loss: 0.534
I1207 04:36:32.383265 140435988830016 train.py:160] Epoch: [ 3] [ 2832/61934] time: 31.63s (950s total) loss: 0.555
I1207 04:37:03.926004 140435988830016 train.py:160] Epoch: [ 3] [ 2932/61934] time: 31.54s (981s total) loss: 1.190
I1207 04:37:35.501507 140435988830016 train.py:160] Epoch: [ 3] [ 3032/61934] time: 31.58s (1013s total) loss: 0.892
I1207 04:38:07.107459 140435988830016 train.py:160] Epoch: [ 3] [ 3132/61934] time: 31.61s (1045s total) loss: 0.527
I1207 04:38:38.682910 140435988830016 train.py:160] Epoch: [ 3] [ 3232/61934] time: 31.58s (1076s total) loss: 0.716
I1207 04:39:10.288164 140435988830016 train.py:160] Epoch: [ 3] [ 3332/61934] time: 31.61s (1108s total) loss: 0.925
I1207 04:39:41.842638 140435988830016 train.py:160] Epoch: [ 3] [ 3432/61934] time: 31.55s (1139s total) loss: 0.851
I1207 04:40:13.349289 140435988830016 train.py:160] Epoch: [ 3] [ 3532/61934] time: 31.51s (1171s total) loss: 0.783
I1207 04:40:44.938398 140435988830016 train.py:160] Epoch: [ 3] [ 3632/61934] time: 31.59s (1202s total) loss: 0.538
I1207 04:41:16.538713 140435988830016 train.py:160] Epoch: [ 3] [ 3732/61934] time: 31.60s (1234s total) loss: 0.587
I1207 04:41:48.110007 140435988830016 train.py:160] Epoch: [ 3] [ 3832/61934] time: 31.57s (1266s total) loss: 0.810
I1207 04:42:19.727085 140435988830016 train.py:160] Epoch: [ 3] [ 3932/61934] time: 31.62s (1297s total) loss: 0.701
I1207 04:42:51.331920 140435988830016 train.py:160] Epoch: [ 3] [ 4032/61934] time: 31.60s (1329s total) loss: 0.674
I1207 04:43:22.959202 140435988830016 train.py:160] Epoch: [ 3] [ 4132/61934] time: 31.63s (1360s total) loss: 0.784
I1207 04:43:54.528147 140435988830016 train.py:160] Epoch: [ 3] [ 4232/61934] time: 31.57s (1392s total) loss: 0.660
I1207 04:44:26.117800 140435988830016 train.py:160] Epoch: [ 3] [ 4332/61934] time: 31.59s (1424s total) loss: 1.016
I1207 04:44:57.829393 140435988830016 train.py:160] Epoch: [ 3] [ 4432/61934] time: 31.71s (1455s total) loss: 0.683
I1207 04:45:29.408393 140435988830016 train.py:160] Epoch: [ 3] [ 4532/61934] time: 31.58s (1487s total) loss: 0.893
I1207 04:46:00.971889 140435988830016 train.py:160] Epoch: [ 3] [ 4632/61934] time: 31.56s (1518s total) loss: 0.811
I1207 04:46:32.657112 140435988830016 train.py:160] Epoch: [ 3] [ 4732/61934] time: 31.69s (1550s total) loss: 0.966
I1207 04:47:04.251636 140435988830016 train.py:160] Epoch: [ 3] [ 4832/61934] time: 31.59s (1582s total) loss: 0.525
I1207 04:47:35.880837 140435988830016 train.py:160] Epoch: [ 3] [ 4932/61934] time: 31.63s (1613s total) loss: 0.681
I1207 04:48:07.468868 140435988830016 train.py:160] Epoch: [ 3] [ 5032/61934] time: 31.59s (1645s total) loss: 0.707
I1207 04:48:39.040953 140435988830016 train.py:160] Epoch: [ 3] [ 5132/61934] time: 31.57s (1676s total) loss: 0.527
I1207 04:49:10.604387 140435988830016 train.py:160] Epoch: [ 3] [ 5232/61934] time: 31.56s (1708s total) loss: 0.777
I1207 04:49:42.215476 140435988830016 train.py:160] Epoch: [ 3] [ 5332/61934] time: 31.61s (1740s total) loss: 0.627
I1207 04:50:13.861568 140435988830016 train.py:160] Epoch: [ 3] [ 5432/61934] time: 31.65s (1771s total) loss: 0.592
I1207 04:50:45.526974 140435988830016 train.py:160] Epoch: [ 3] [ 5532/61934] time: 31.67s (1803s total) loss: 0.437
I1207 04:51:17.161700 140435988830016 train.py:160] Epoch: [ 3] [ 5632/61934] time: 31.63s (1835s total) loss: 0.727
I1207 04:51:48.781478 140435988830016 train.py:160] Epoch: [ 3] [ 5732/61934] time: 31.62s (1866s total) loss: 0.862
I1207 04:52:20.336378 140435988830016 train.py:160] Epoch: [ 3] [ 5832/61934] time: 31.55s (1898s total) loss: 0.463
I1207 04:52:51.982495 140435988830016 train.py:160] Epoch: [ 3] [ 5932/61934] time: 31.65s (1929s total) loss: 0.646
I1207 04:53:23.521778 140435988830016 train.py:160] Epoch: [ 3] [ 6032/61934] time: 31.54s (1961s total) loss: 0.748
I1207 04:53:55.091021 140435988830016 train.py:160] Epoch: [ 3] [ 6132/61934] time: 31.57s (1993s total) loss: 0.598
I1207 04:54:26.676370 140435988830016 train.py:160] Epoch: [ 3] [ 6232/61934] time: 31.59s (2024s total) loss: 0.745
I1207 04:54:58.284981 140435988830016 train.py:160] Epoch: [ 3] [ 6332/61934] time: 31.61s (2056s total) loss: 0.571
I1207 04:55:29.947764 140435988830016 train.py:160] Epoch: [ 3] [ 6432/61934] time: 31.66s (2087s total) loss: 0.552
I1207 04:56:01.537599 140435988830016 train.py:160] Epoch: [ 3] [ 6532/61934] time: 31.59s (2119s total) loss: 0.574
I1207 04:56:33.155027 140435988830016 train.py:160] Epoch: [ 3] [ 6632/61934] time: 31.62s (2151s total) loss: 0.717
I1207 04:57:04.683973 140435988830016 train.py:160] Epoch: [ 3] [ 6732/61934] time: 31.53s (2182s total) loss: 0.723
I1207 04:57:36.353315 140435988830016 train.py:160] Epoch: [ 3] [ 6832/61934] time: 31.67s (2214s total) loss: 0.734
I1207 04:58:08.024360 140435988830016 train.py:160] Epoch: [ 3] [ 6932/61934] time: 31.67s (2245s total) loss: 0.647
I1207 04:58:39.667109 140435988830016 train.py:160] Epoch: [ 3] [ 7032/61934] time: 31.64s (2277s total) loss: 0.601
I1207 04:59:11.321601 140435988830016 train.py:160] Epoch: [ 3] [ 7132/61934] time: 31.65s (2309s total) loss: 0.470
I1207 04:59:42.875149 140435988830016 train.py:160] Epoch: [ 3] [ 7232/61934] time: 31.55s (2340s total) loss: 0.679
I1207 05:00:14.462999 140435988830016 train.py:160] Epoch: [ 3] [ 7332/61934] time: 31.59s (2372s total) loss: 0.615
I1207 05:00:46.003810 140435988830016 train.py:160] Epoch: [ 3] [ 7432/61934] time: 31.54s (2403s total) loss: 0.581
I1207 05:01:17.647250 140435988830016 train.py:160] Epoch: [ 3] [ 7532/61934] time: 31.64s (2435s total) loss: 0.627
I1207 05:01:49.288669 140435988830016 train.py:160] Epoch: [ 3] [ 7632/61934] time: 31.64s (2467s total) loss: 0.684
I1207 05:02:20.847205 140435988830016 train.py:160] Epoch: [ 3] [ 7732/61934] time: 31.56s (2498s total) loss: 0.727
I1207 05:02:52.439890 140435988830016 train.py:160] Epoch: [ 3] [ 7832/61934] time: 31.59s (2530s total) loss: 0.768
I1207 05:03:24.075944 140435988830016 train.py:160] Epoch: [ 3] [ 7932/61934] time: 31.64s (2562s total) loss: 0.630
I1207 05:03:55.700625 140435988830016 train.py:160] Epoch: [ 3] [ 8032/61934] time: 31.62s (2593s total) loss: 0.642
I1207 05:04:27.282137 140435988830016 train.py:160] Epoch: [ 3] [ 8132/61934] time: 31.58s (2625s total) loss: 0.674
I1207 05:04:58.946686 140435988830016 train.py:160] Epoch: [ 3] [ 8232/61934] time: 31.66s (2656s total) loss: 0.811
I1207 05:05:30.542384 140435988830016 train.py:160] Epoch: [ 3] [ 8332/61934] time: 31.60s (2688s total) loss: 0.667
I1207 05:06:02.108391 140435988830016 train.py:160] Epoch: [ 3] [ 8432/61934] time: 31.57s (2720s total) loss: 0.682
I1207 05:06:33.833221 140435988830016 train.py:160] Epoch: [ 3] [ 8532/61934] time: 31.72s (2751s total) loss: 0.556
I1207 05:07:05.392759 140435988830016 train.py:160] Epoch: [ 3] [ 8632/61934] time: 31.56s (2783s total) loss: 0.474
I1207 05:07:37.124710 140435988830016 train.py:160] Epoch: [ 3] [ 8732/61934] time: 31.73s (2815s total) loss: 0.835
I1207 05:08:08.672189 140435988830016 train.py:160] Epoch: [ 3] [ 8832/61934] time: 31.55s (2846s total) loss: 0.793
I1207 05:08:40.325237 140435988830016 train.py:160] Epoch: [ 3] [ 8932/61934] time: 31.65s (2878s total) loss: 1.361
I1207 05:09:11.922495 140435988830016 train.py:160] Epoch: [ 3] [ 9032/61934] time: 31.60s (2909s total) loss: 0.607
I1207 05:09:43.490735 140435988830016 train.py:160] Epoch: [ 3] [ 9132/61934] time: 31.57s (2941s total) loss: 0.740
I1207 05:10:15.064886 140435988830016 train.py:160] Epoch: [ 3] [ 9232/61934] time: 31.57s (2973s total) loss: 0.586
I1207 05:10:46.720016 140435988830016 train.py:160] Epoch: [ 3] [ 9332/61934] time: 31.66s (3004s total) loss: 0.597
I1207 05:11:18.290343 140435988830016 train.py:160] Epoch: [ 3] [ 9432/61934] time: 31.57s (3036s total) loss: 0.674
I1207 05:11:49.911958 140435988830016 train.py:160] Epoch: [ 3] [ 9532/61934] time: 31.62s (3067s total) loss: 0.684
I1207 05:12:21.558531 140435988830016 train.py:160] Epoch: [ 3] [ 9632/61934] time: 31.65s (3099s total) loss: 0.684
I1207 05:12:53.135204 140435988830016 train.py:160] Epoch: [ 3] [ 9732/61934] time: 31.58s (3131s total) loss: 0.591
I1207 05:13:24.695152 140435988830016 train.py:160] Epoch: [ 3] [ 9832/61934] time: 31.56s (3162s total) loss: 0.613
I1207 05:13:56.367587 140435988830016 train.py:160] Epoch: [ 3] [ 9932/61934] time: 31.67s (3194s total) loss: 0.745
I1207 05:14:28.043583 140435988830016 train.py:160] Epoch: [ 3] [10032/61934] time: 31.68s (3225s total) loss: 0.716
I1207 05:14:59.691251 140435988830016 train.py:160] Epoch: [ 3] [10132/61934] time: 31.65s (3257s total) loss: 0.631
I1207 05:15:31.310742 140435988830016 train.py:160] Epoch: [ 3] [10232/61934] time: 31.62s (3289s total) loss: 0.798
I1207 05:16:03.059670 140435988830016 train.py:160] Epoch: [ 3] [10332/61934] time: 31.75s (3321s total) loss: 0.684
I1207 05:16:34.694396 140435988830016 train.py:160] Epoch: [ 3] [10432/61934] time: 31.63s (3352s total) loss: 0.458
I1207 05:17:06.275713 140435988830016 train.py:160] Epoch: [ 3] [10532/61934] time: 31.58s (3384s total) loss: 0.666
I1207 05:17:37.832996 140435988830016 train.py:160] Epoch: [ 3] [10632/61934] time: 31.56s (3415s total) loss: 0.815
I1207 05:18:09.486561 140435988830016 train.py:160] Epoch: [ 3] [10732/61934] time: 31.65s (3447s total) loss: 0.670
I1207 05:18:41.104695 140435988830016 train.py:160] Epoch: [ 3] [10832/61934] time: 31.62s (3479s total) loss: 0.560
I1207 05:19:12.698879 140435988830016 train.py:160] Epoch: [ 3] [10932/61934] time: 31.59s (3510s total) loss: 0.686
I1207 05:19:44.250583 140435988830016 train.py:160] Epoch: [ 3] [11032/61934] time: 31.55s (3542s total) loss: 1.013
I1207 05:20:15.831093 140435988830016 train.py:160] Epoch: [ 3] [11132/61934] time: 31.58s (3573s total) loss: 0.752
I1207 05:20:47.439536 140435988830016 train.py:160] Epoch: [ 3] [11232/61934] time: 31.61s (3605s total) loss: 0.498
I1207 05:21:19.040710 140435988830016 train.py:160] Epoch: [ 3] [11332/61934] time: 31.60s (3636s total) loss: 0.526
I1207 05:21:50.624261 140435988830016 train.py:160] Epoch: [ 3] [11432/61934] time: 31.58s (3668s total) loss: 0.702
I1207 05:22:22.238183 140435988830016 train.py:160] Epoch: [ 3] [11532/61934] time: 31.61s (3700s total) loss: 0.876
I1207 05:22:54.000700 140435988830016 train.py:160] Epoch: [ 3] [11632/61934] time: 31.76s (3731s total) loss: 0.428
I1207 05:23:25.536289 140435988830016 train.py:160] Epoch: [ 3] [11732/61934] time: 31.54s (3763s total) loss: 0.548
I1207 05:23:57.072982 140435988830016 train.py:160] Epoch: [ 3] [11832/61934] time: 31.54s (3795s total) loss: 0.549
I1207 05:24:28.633112 140435988830016 train.py:160] Epoch: [ 3] [11932/61934] time: 31.56s (3826s total) loss: 0.611
I1207 05:25:00.333991 140435988830016 train.py:160] Epoch: [ 3] [12032/61934] time: 31.70s (3858s total) loss: 0.563
I1207 05:25:31.955066 140435988830016 train.py:160] Epoch: [ 3] [12132/61934] time: 31.62s (3889s total) loss: 0.806
I1207 05:26:03.578795 140435988830016 train.py:160] Epoch: [ 3] [12232/61934] time: 31.62s (3921s total) loss: 0.944
I1207 05:26:35.156766 140435988830016 train.py:160] Epoch: [ 3] [12332/61934] time: 31.58s (3953s total) loss: 0.565
I1207 05:27:06.732634 140435988830016 train.py:160] Epoch: [ 3] [12432/61934] time: 31.58s (3984s total) loss: 1.199
I1207 05:27:38.274991 140435988830016 train.py:160] Epoch: [ 3] [12532/61934] time: 31.54s (4016s total) loss: 0.616
I1207 05:28:09.886255 140435988830016 train.py:160] Epoch: [ 3] [12632/61934] time: 31.61s (4047s total) loss: 0.505
I1207 05:28:41.407544 140435988830016 train.py:160] Epoch: [ 3] [12732/61934] time: 31.52s (4079s total) loss: 0.592
I1207 05:29:13.141935 140435988830016 train.py:160] Epoch: [ 3] [12832/61934] time: 31.73s (4111s total) loss: 1.047
I1207 05:29:44.728935 140435988830016 train.py:160] Epoch: [ 3] [12932/61934] time: 31.59s (4142s total) loss: 0.529
I1207 05:30:16.313750 140435988830016 train.py:160] Epoch: [ 3] [13032/61934] time: 31.58s (4174s total) loss: 0.706
I1207 05:30:47.813818 140435988830016 train.py:160] Epoch: [ 3] [13132/61934] time: 31.50s (4205s total) loss: 0.548
I1207 05:31:19.387364 140435988830016 train.py:160] Epoch: [ 3] [13232/61934] time: 31.57s (4237s total) loss: 0.584
I1207 05:31:51.046510 140435988830016 train.py:160] Epoch: [ 3] [13332/61934] time: 31.66s (4268s total) loss: 0.749
I1207 05:32:22.725842 140435988830016 train.py:160] Epoch: [ 3] [13432/61934] time: 31.68s (4300s total) loss: 0.824
I1207 05:32:54.279202 140435988830016 train.py:160] Epoch: [ 3] [13532/61934] time: 31.55s (4332s total) loss: 0.769
I1207 05:33:25.874742 140435988830016 train.py:160] Epoch: [ 3] [13632/61934] time: 31.60s (4363s total) loss: 0.819
I1207 05:33:57.520894 140435988830016 train.py:160] Epoch: [ 3] [13732/61934] time: 31.65s (4395s total) loss: 0.689
I1207 05:34:29.327107 140435988830016 train.py:160] Epoch: [ 3] [13832/61934] time: 31.81s (4427s total) loss: 0.557
I1207 05:35:01.037793 140435988830016 train.py:160] Epoch: [ 3] [13932/61934] time: 31.71s (4458s total) loss: 0.817
I1207 05:35:32.568149 140435988830016 train.py:160] Epoch: [ 3] [14032/61934] time: 31.53s (4490s total) loss: 0.780
I1207 05:36:04.144195 140435988830016 train.py:160] Epoch: [ 3] [14132/61934] time: 31.58s (4522s total) loss: 0.622
I1207 05:36:35.769748 140435988830016 train.py:160] Epoch: [ 3] [14232/61934] time: 31.63s (4553s total) loss: 0.666
I1207 05:37:07.444393 140435988830016 train.py:160] Epoch: [ 3] [14332/61934] time: 31.67s (4585s total) loss: 0.823
I1207 05:37:39.059886 140435988830016 train.py:160] Epoch: [ 3] [14432/61934] time: 31.62s (4617s total) loss: 0.691
I1207 05:38:10.668534 140435988830016 train.py:160] Epoch: [ 3] [14532/61934] time: 31.61s (4648s total) loss: 0.736
I1207 05:38:42.231716 140435988830016 train.py:160] Epoch: [ 3] [14632/61934] time: 31.56s (4680s total) loss: 0.948
I1207 05:39:13.862091 140435988830016 train.py:160] Epoch: [ 3] [14732/61934] time: 31.63s (4711s total) loss: 0.580
I1207 05:39:45.515132 140435988830016 train.py:160] Epoch: [ 3] [14832/61934] time: 31.65s (4743s total) loss: 0.876
I1207 05:40:17.270043 140435988830016 train.py:160] Epoch: [ 3] [14932/61934] time: 31.75s (4775s total) loss: 0.730
I1207 05:40:48.878081 140435988830016 train.py:160] Epoch: [ 3] [15032/61934] time: 31.61s (4806s total) loss: 0.537
I1207 05:41:20.397296 140435988830016 train.py:160] Epoch: [ 3] [15132/61934] time: 31.52s (4838s total) loss: 0.663
I1207 05:41:51.904309 140435988830016 train.py:160] Epoch: [ 3] [15232/61934] time: 31.51s (4869s total) loss: 0.698
I1207 05:42:23.458225 140435988830016 train.py:160] Epoch: [ 3] [15332/61934] time: 31.55s (4901s total) loss: 0.595
I1207 05:42:55.066397 140435988830016 train.py:160] Epoch: [ 3] [15432/61934] time: 31.61s (4933s total) loss: 0.653
I1207 05:43:26.630458 140435988830016 train.py:160] Epoch: [ 3] [15532/61934] time: 31.56s (4964s total) loss: 0.641
I1207 05:43:58.192289 140435988830016 train.py:160] Epoch: [ 3] [15632/61934] time: 31.56s (4996s total) loss: 1.011
I1207 05:44:29.697813 140435988830016 train.py:160] Epoch: [ 3] [15732/61934] time: 31.51s (5027s total) loss: 1.057
I1207 05:45:01.196463 140435988830016 train.py:160] Epoch: [ 3] [15832/61934] time: 31.50s (5059s total) loss: 0.499
I1207 05:45:32.743935 140435988830016 train.py:160] Epoch: [ 3] [15932/61934] time: 31.55s (5090s total) loss: 0.608
I1207 05:46:04.339363 140435988830016 train.py:160] Epoch: [ 3] [16032/61934] time: 31.60s (5122s total) loss: 0.673
I1207 05:46:35.864361 140435988830016 train.py:160] Epoch: [ 3] [16132/61934] time: 31.53s (5153s total) loss: 0.785
I1207 05:47:07.465914 140435988830016 train.py:160] Epoch: [ 3] [16232/61934] time: 31.60s (5185s total) loss: 0.639
I1207 05:47:39.019253 140435988830016 train.py:160] Epoch: [ 3] [16332/61934] time: 31.55s (5216s total) loss: 0.617
I1207 05:48:10.664088 140435988830016 train.py:160] Epoch: [ 3] [16432/61934] time: 31.64s (5248s total) loss: 0.594
I1207 05:48:42.211250 140435988830016 train.py:160] Epoch: [ 3] [16532/61934] time: 31.55s (5280s total) loss: 0.695
I1207 05:49:13.959392 140435988830016 train.py:160] Epoch: [ 3] [16632/61934] time: 31.75s (5311s total) loss: 0.494
I1207 05:49:45.493944 140435988830016 train.py:160] Epoch: [ 3] [16732/61934] time: 31.53s (5343s total) loss: 0.834
I1207 05:50:17.125608 140435988830016 train.py:160] Epoch: [ 3] [16832/61934] time: 31.63s (5375s total) loss: 0.756
I1207 05:50:48.729122 140435988830016 train.py:160] Epoch: [ 3] [16932/61934] time: 31.60s (5406s total) loss: 1.503
I1207 05:51:20.333257 140435988830016 train.py:160] Epoch: [ 3] [17032/61934] time: 31.60s (5438s total) loss: 0.582
I1207 05:51:51.934559 140435988830016 train.py:160] Epoch: [ 3] [17132/61934] time: 31.60s (5469s total) loss: 0.718
I1207 05:52:23.494415 140435988830016 train.py:160] Epoch: [ 3] [17232/61934] time: 31.56s (5501s total) loss: 0.656
I1207 05:52:55.162442 140435988830016 train.py:160] Epoch: [ 3] [17332/61934] time: 31.67s (5533s total) loss: 0.938
I1207 05:53:26.721386 140435988830016 train.py:160] Epoch: [ 3] [17432/61934] time: 31.56s (5564s total) loss: 0.751
I1207 05:53:58.353583 140435988830016 train.py:160] Epoch: [ 3] [17532/61934] time: 31.63s (5596s total) loss: 0.516
I1207 05:54:29.991661 140435988830016 train.py:160] Epoch: [ 3] [17632/61934] time: 31.64s (5627s total) loss: 0.669
I1207 05:55:01.561665 140435988830016 train.py:160] Epoch: [ 3] [17732/61934] time: 31.57s (5659s total) loss: 0.740
I1207 05:55:33.090273 140435988830016 train.py:160] Epoch: [ 3] [17832/61934] time: 31.53s (5691s total) loss: 0.577
I1207 05:56:04.635252 140435988830016 train.py:160] Epoch: [ 3] [17932/61934] time: 31.54s (5722s total) loss: 0.609
I1207 05:56:36.228234 140435988830016 train.py:160] Epoch: [ 3] [18032/61934] time: 31.59s (5754s total) loss: 0.761
I1207 05:57:07.811052 140435988830016 train.py:160] Epoch: [ 3] [18132/61934] time: 31.58s (5785s total) loss: 0.715
I1207 05:57:39.411499 140435988830016 train.py:160] Epoch: [ 3] [18232/61934] time: 31.60s (5817s total) loss: 0.687
I1207 05:58:11.065181 140435988830016 train.py:160] Epoch: [ 3] [18332/61934] time: 31.65s (5849s total) loss: 0.582
I1207 05:58:42.644834 140435988830016 train.py:160] Epoch: [ 3] [18432/61934] time: 31.58s (5880s total) loss: 0.835
I1207 05:59:14.231221 140435988830016 train.py:160] Epoch: [ 3] [18532/61934] time: 31.59s (5912s total) loss: 0.679
I1207 05:59:45.800315 140435988830016 train.py:160] Epoch: [ 3] [18632/61934] time: 31.57s (5943s total) loss: 0.625
I1207 06:00:17.483471 140435988830016 train.py:160] Epoch: [ 3] [18732/61934] time: 31.68s (5975s total) loss: 0.869
I1207 06:00:49.029124 140435988830016 train.py:160] Epoch: [ 3] [18832/61934] time: 31.55s (6006s total) loss: 0.930
I1207 06:01:20.600784 140435988830016 train.py:160] Epoch: [ 3] [18932/61934] time: 31.57s (6038s total) loss: 0.783
I1207 06:01:52.124969 140435988830016 train.py:160] Epoch: [ 3] [19032/61934] time: 31.52s (6070s total) loss: 0.646
I1207 06:02:23.815009 140435988830016 train.py:160] Epoch: [ 3] [19132/61934] time: 31.69s (6101s total) loss: 0.584
I1207 06:02:55.355379 140435988830016 train.py:160] Epoch: [ 3] [19232/61934] time: 31.54s (6133s total) loss: 0.570
I1207 06:03:27.029088 140435988830016 train.py:160] Epoch: [ 3] [19332/61934] time: 31.67s (6164s total) loss: 0.696
I1207 06:03:58.666562 140435988830016 train.py:160] Epoch: [ 3] [19432/61934] time: 31.64s (6196s total) loss: 0.619
I1207 06:04:30.291645 140435988830016 train.py:160] Epoch: [ 3] [19532/61934] time: 31.63s (6228s total) loss: 0.488
I1207 06:05:02.027705 140435988830016 train.py:160] Epoch: [ 3] [19632/61934] time: 31.74s (6259s total) loss: 0.510
I1207 06:05:33.620808 140435988830016 train.py:160] Epoch: [ 3] [19732/61934] time: 31.59s (6291s total) loss: 1.008
I1207 06:06:05.200258 140435988830016 train.py:160] Epoch: [ 3] [19832/61934] time: 31.58s (6323s total) loss: 0.573
I1207 06:06:36.876619 140435988830016 train.py:160] Epoch: [ 3] [19932/61934] time: 31.68s (6354s total) loss: 0.695
I1207 06:07:08.486910 140435988830016 train.py:160] Epoch: [ 3] [20032/61934] time: 31.61s (6386s total) loss: 0.735
I1207 06:07:40.094301 140435988830016 train.py:160] Epoch: [ 3] [20132/61934] time: 31.61s (6418s total) loss: 0.926
I1207 06:08:11.743989 140435988830016 train.py:160] Epoch: [ 3] [20232/61934] time: 31.65s (6449s total) loss: 0.386
I1207 06:08:43.391137 140435988830016 train.py:160] Epoch: [ 3] [20332/61934] time: 31.65s (6481s total) loss: 0.777
I1207 06:09:14.967019 140435988830016 train.py:160] Epoch: [ 3] [20432/61934] time: 31.58s (6512s total) loss: 0.601
I1207 06:09:46.583923 140435988830016 train.py:160] Epoch: [ 3] [20532/61934] time: 31.62s (6544s total) loss: 0.704
I1207 06:10:18.409764 140435988830016 train.py:160] Epoch: [ 3] [20632/61934] time: 31.83s (6576s total) loss: 0.468
I1207 06:10:50.205856 140435988830016 train.py:160] Epoch: [ 3] [20732/61934] time: 31.80s (6608s total) loss: 0.707
I1207 06:11:21.702259 140435988830016 train.py:160] Epoch: [ 3] [20832/61934] time: 31.50s (6639s total) loss: 0.679
I1207 06:11:53.436704 140435988830016 train.py:160] Epoch: [ 3] [20932/61934] time: 31.73s (6671s total) loss: 0.695
I1207 06:12:25.049620 140435988830016 train.py:160] Epoch: [ 3] [21032/61934] time: 31.61s (6702s total) loss: 0.710
I1207 06:12:56.665453 140435988830016 train.py:160] Epoch: [ 3] [21132/61934] time: 31.62s (6734s total) loss: 0.670
I1207 06:13:28.260435 140435988830016 train.py:160] Epoch: [ 3] [21232/61934] time: 31.59s (6766s total) loss: 0.752
I1207 06:13:59.839249 140435988830016 train.py:160] Epoch: [ 3] [21332/61934] time: 31.58s (6797s total) loss: 0.848
I1207 06:14:31.583571 140435988830016 train.py:160] Epoch: [ 3] [21432/61934] time: 31.74s (6829s total) loss: 0.807
I1207 06:15:03.296856 140435988830016 train.py:160] Epoch: [ 3] [21532/61934] time: 31.71s (6861s total) loss: 0.542
I1207 06:15:34.896457 140435988830016 train.py:160] Epoch: [ 3] [21632/61934] time: 31.60s (6892s total) loss: 0.503
I1207 06:16:06.528445 140435988830016 train.py:160] Epoch: [ 3] [21732/61934] time: 31.63s (6924s total) loss: 0.791
I1207 06:16:38.074195 140435988830016 train.py:160] Epoch: [ 3] [21832/61934] time: 31.55s (6956s total) loss: 1.256
I1207 06:17:09.661091 140435988830016 train.py:160] Epoch: [ 3] [21932/61934] time: 31.59s (6987s total) loss: 0.723
I1207 06:17:41.332053 140435988830016 train.py:160] Epoch: [ 3] [22032/61934] time: 31.67s (7019s total) loss: 0.709
I1207 06:18:12.877549 140435988830016 train.py:160] Epoch: [ 3] [22132/61934] time: 31.55s (7050s total) loss: 0.760
I1207 06:18:44.626963 140435988830016 train.py:160] Epoch: [ 3] [22232/61934] time: 31.75s (7082s total) loss: 0.478
I1207 06:19:16.161853 140435988830016 train.py:160] Epoch: [ 3] [22332/61934] time: 31.53s (7114s total) loss: 0.904
I1207 06:19:47.762571 140435988830016 train.py:160] Epoch: [ 3] [22432/61934] time: 31.60s (7145s total) loss: 0.567
I1207 06:20:19.365950 140435988830016 train.py:160] Epoch: [ 3] [22532/61934] time: 31.60s (7177s total) loss: 0.710
I1207 06:20:51.102500 140435988830016 train.py:160] Epoch: [ 3] [22632/61934] time: 31.74s (7209s total) loss: 0.684
I1207 06:21:22.787088 140435988830016 train.py:160] Epoch: [ 3] [22732/61934] time: 31.68s (7240s total) loss: 0.657
I1207 06:21:54.368520 140435988830016 train.py:160] Epoch: [ 3] [22832/61934] time: 31.58s (7272s total) loss: 0.496
I1207 06:22:25.935018 140435988830016 train.py:160] Epoch: [ 3] [22932/61934] time: 31.57s (7303s total) loss: 0.550
I1207 06:22:57.522805 140435988830016 train.py:160] Epoch: [ 3] [23032/61934] time: 31.59s (7335s total) loss: 0.681
I1207 06:23:29.104449 140435988830016 train.py:160] Epoch: [ 3] [23132/61934] time: 31.58s (7367s total) loss: 0.694
I1207 06:24:00.812192 140435988830016 train.py:160] Epoch: [ 3] [23232/61934] time: 31.71s (7398s total) loss: 0.787
I1207 06:24:32.304950 140435988830016 train.py:160] Epoch: [ 3] [23332/61934] time: 31.49s (7430s total) loss: 0.964
I1207 06:25:03.918474 140435988830016 train.py:160] Epoch: [ 3] [23432/61934] time: 31.61s (7461s total) loss: 0.656
I1207 06:25:35.497394 140435988830016 train.py:160] Epoch: [ 3] [23532/61934] time: 31.58s (7493s total) loss: 0.438
I1207 06:26:07.101759 140435988830016 train.py:160] Epoch: [ 3] [23632/61934] time: 31.60s (7525s total) loss: 0.546
I1207 06:26:38.713882 140435988830016 train.py:160] Epoch: [ 3] [23732/61934] time: 31.61s (7556s total) loss: 0.670
I1207 06:27:10.200520 140435988830016 train.py:160] Epoch: [ 3] [23832/61934] time: 31.49s (7588s total) loss: 0.724
I1207 06:27:41.782657 140435988830016 train.py:160] Epoch: [ 3] [23932/61934] time: 31.58s (7619s total) loss: 0.668
I1207 06:28:13.390752 140435988830016 train.py:160] Epoch: [ 3] [24032/61934] time: 31.61s (7651s total) loss: 0.596
I1207 06:28:44.917360 140435988830016 train.py:160] Epoch: [ 3] [24132/61934] time: 31.53s (7682s total) loss: 0.842
I1207 06:29:16.494117 140435988830016 train.py:160] Epoch: [ 3] [24232/61934] time: 31.58s (7714s total) loss: 0.927
I1207 06:29:48.019706 140435988830016 train.py:160] Epoch: [ 3] [24332/61934] time: 31.53s (7745s total) loss: 0.673
I1207 06:30:19.600101 140435988830016 train.py:160] Epoch: [ 3] [24432/61934] time: 31.58s (7777s total) loss: 0.639
I1207 06:30:51.267334 140435988830016 train.py:160] Epoch: [ 3] [24532/61934] time: 31.67s (7809s total) loss: 0.748
I1207 06:31:22.760207 140435988830016 train.py:160] Epoch: [ 3] [24632/61934] time: 31.49s (7840s total) loss: 0.697
I1207 06:31:54.286255 140435988830016 train.py:160] Epoch: [ 3] [24732/61934] time: 31.53s (7872s total) loss: 1.017
I1207 06:32:25.854366 140435988830016 train.py:160] Epoch: [ 3] [24832/61934] time: 31.57s (7903s total) loss: 0.640
I1207 06:32:57.403506 140435988830016 train.py:160] Epoch: [ 3] [24932/61934] time: 31.55s (7935s total) loss: 0.690
I1207 06:33:29.084853 140435988830016 train.py:160] Epoch: [ 3] [25032/61934] time: 31.68s (7967s total) loss: 0.932
I1207 06:34:00.542106 140435988830016 train.py:160] Epoch: [ 3] [25132/61934] time: 31.46s (7998s total) loss: 0.741
I1207 06:34:32.092538 140435988830016 train.py:160] Epoch: [ 3] [25232/61934] time: 31.55s (8030s total) loss: 0.577
I1207 06:35:03.902321 140435988830016 train.py:160] Epoch: [ 3] [25332/61934] time: 31.81s (8061s total) loss: 0.820
I1207 06:35:35.397669 140435988830016 train.py:160] Epoch: [ 3] [25432/61934] time: 31.50s (8093s total) loss: 0.382
I1207 06:36:07.015404 140435988830016 train.py:160] Epoch: [ 3] [25532/61934] time: 31.62s (8124s total) loss: 0.564
I1207 06:36:38.658855 140435988830016 train.py:160] Epoch: [ 3] [25632/61934] time: 31.64s (8156s total) loss: 0.566
I1207 06:37:10.264813 140435988830016 train.py:160] Epoch: [ 3] [25732/61934] time: 31.61s (8188s total) loss: 0.543
I1207 06:37:41.721156 140435988830016 train.py:160] Epoch: [ 3] [25832/61934] time: 31.46s (8219s total) loss: 0.715
I1207 06:38:13.291435 140435988830016 train.py:160] Epoch: [ 3] [25932/61934] time: 31.57s (8251s total) loss: 0.603
I1207 06:38:44.925922 140435988830016 train.py:160] Epoch: [ 3] [26032/61934] time: 31.63s (8282s total) loss: 0.700
I1207 06:39:16.517026 140435988830016 train.py:160] Epoch: [ 3] [26132/61934] time: 31.59s (8314s total) loss: 0.537
I1207 06:39:48.142779 140435988830016 train.py:160] Epoch: [ 3] [26232/61934] time: 31.63s (8346s total) loss: 0.762
I1207 06:40:19.721150 140435988830016 train.py:160] Epoch: [ 3] [26332/61934] time: 31.58s (8377s total) loss: 0.758
I1207 06:40:51.337670 140435988830016 train.py:160] Epoch: [ 3] [26432/61934] time: 31.62s (8409s total) loss: 0.654
I1207 06:41:23.018301 140435988830016 train.py:160] Epoch: [ 3] [26532/61934] time: 31.68s (8440s total) loss: 0.810
I1207 06:41:54.630928 140435988830016 train.py:160] Epoch: [ 3] [26632/61934] time: 31.61s (8472s total) loss: 0.602
I1207 06:42:26.239611 140435988830016 train.py:160] Epoch: [ 3] [26732/61934] time: 31.61s (8504s total) loss: 0.743
I1207 06:42:57.860519 140435988830016 train.py:160] Epoch: [ 3] [26832/61934] time: 31.62s (8535s total) loss: 0.763
I1207 06:43:29.604176 140435988830016 train.py:160] Epoch: [ 3] [26932/61934] time: 31.74s (8567s total) loss: 0.496
I1207 06:44:01.190018 140435988830016 train.py:160] Epoch: [ 3] [27032/61934] time: 31.59s (8599s total) loss: 0.620
I1207 06:44:32.732589 140435988830016 train.py:160] Epoch: [ 3] [27132/61934] time: 31.54s (8630s total) loss: 0.519
I1207 06:45:04.299675 140435988830016 train.py:160] Epoch: [ 3] [27232/61934] time: 31.57s (8662s total) loss: 0.470
I1207 06:45:35.822357 140435988830016 train.py:160] Epoch: [ 3] [27332/61934] time: 31.52s (8693s total) loss: 0.986
I1207 06:46:07.377291 140435988830016 train.py:160] Epoch: [ 3] [27432/61934] time: 31.55s (8725s total) loss: 0.586
I1207 06:46:38.977354 140435988830016 train.py:160] Epoch: [ 3] [27532/61934] time: 31.60s (8756s total) loss: 0.597
I1207 06:47:10.475752 140435988830016 train.py:160] Epoch: [ 3] [27632/61934] time: 31.50s (8788s total) loss: 0.618
I1207 06:47:42.186501 140435988830016 train.py:160] Epoch: [ 3] [27732/61934] time: 31.71s (8820s total) loss: 0.925
I1207 06:48:13.661389 140435988830016 train.py:160] Epoch: [ 3] [27832/61934] time: 31.48s (8851s total) loss: 1.092
I1207 06:48:45.219400 140435988830016 train.py:160] Epoch: [ 3] [27932/61934] time: 31.56s (8883s total) loss: 0.595
I1207 06:49:16.833121 140435988830016 train.py:160] Epoch: [ 3] [28032/61934] time: 31.61s (8914s total) loss: 0.743
I1207 06:49:48.447695 140435988830016 train.py:160] Epoch: [ 3] [28132/61934] time: 31.61s (8946s total) loss: 0.739
I1207 06:50:20.022248 140435988830016 train.py:160] Epoch: [ 3] [28232/61934] time: 31.57s (8977s total) loss: 0.907
I1207 06:50:51.697616 140435988830016 train.py:160] Epoch: [ 3] [28332/61934] time: 31.68s (9009s total) loss: 0.509
I1207 06:51:23.585805 140435988830016 train.py:160] Epoch: [ 3] [28432/61934] time: 31.89s (9041s total) loss: 0.836
I1207 06:51:55.436598 140435988830016 train.py:160] Epoch: [ 3] [28532/61934] time: 31.85s (9073s total) loss: 0.642
I1207 06:52:27.299291 140435988830016 train.py:160] Epoch: [ 3] [28632/61934] time: 31.86s (9105s total) loss: 0.739
I1207 06:52:59.220578 140435988830016 train.py:160] Epoch: [ 3] [28732/61934] time: 31.92s (9137s total) loss: 0.799
I1207 06:53:31.279464 140435988830016 train.py:160] Epoch: [ 3] [28832/61934] time: 32.06s (9169s total) loss: 0.754
I1207 06:54:03.130451 140435988830016 train.py:160] Epoch: [ 3] [28932/61934] time: 31.85s (9201s total) loss: 0.732
I1207 06:54:35.121221 140435988830016 train.py:160] Epoch: [ 3] [29032/61934] time: 31.99s (9233s total) loss: 0.467
I1207 06:55:06.941784 140435988830016 train.py:160] Epoch: [ 3] [29132/61934] time: 31.82s (9264s total) loss: 0.623
I1207 06:55:38.880305 140435988830016 train.py:160] Epoch: [ 3] [29232/61934] time: 31.94s (9296s total) loss: 0.813
I1207 06:56:10.741023 140435988830016 train.py:160] Epoch: [ 3] [29332/61934] time: 31.86s (9328s total) loss: 0.521
I1207 06:56:42.665210 140435988830016 train.py:160] Epoch: [ 3] [29432/61934] time: 31.92s (9360s total) loss: 0.692
I1207 06:57:14.523293 140435988830016 train.py:160] Epoch: [ 3] [29532/61934] time: 31.86s (9392s total) loss: 0.551
I1207 06:57:46.349563 140435988830016 train.py:160] Epoch: [ 3] [29632/61934] time: 31.83s (9424s total) loss: 0.556
I1207 06:58:18.311299 140435988830016 train.py:160] Epoch: [ 3] [29732/61934] time: 31.96s (9456s total) loss: 0.846
I1207 06:58:50.161784 140435988830016 train.py:160] Epoch: [ 3] [29832/61934] time: 31.85s (9488s total) loss: 1.074
I1207 06:59:21.971542 140435988830016 train.py:160] Epoch: [ 3] [29932/61934] time: 31.81s (9519s total) loss: 0.498
I1207 06:59:53.804362 140435988830016 train.py:160] Epoch: [ 3] [30032/61934] time: 31.83s (9551s total) loss: 0.847
I1207 07:00:25.750699 140435988830016 train.py:160] Epoch: [ 3] [30132/61934] time: 31.95s (9583s total) loss: 0.774
I1207 07:00:57.700006 140435988830016 train.py:160] Epoch: [ 3] [30232/61934] time: 31.95s (9615s total) loss: 0.501
I1207 07:01:29.754544 140435988830016 train.py:160] Epoch: [ 3] [30332/61934] time: 32.05s (9647s total) loss: 0.734
I1207 07:02:01.734633 140435988830016 train.py:160] Epoch: [ 3] [30432/61934] time: 31.98s (9679s total) loss: 0.647
I1207 07:02:33.880220 140435988830016 train.py:160] Epoch: [ 3] [30532/61934] time: 32.15s (9711s total) loss: 0.492
I1207 07:03:05.752621 140435988830016 train.py:160] Epoch: [ 3] [30632/61934] time: 31.87s (9743s total) loss: 0.572
I1207 07:03:37.542846 140435988830016 train.py:160] Epoch: [ 3] [30732/61934] time: 31.79s (9775s total) loss: 0.909
I1207 07:04:09.436374 140435988830016 train.py:160] Epoch: [ 3] [30832/61934] time: 31.89s (9807s total) loss: 0.615
I1207 07:04:41.392255 140435988830016 train.py:160] Epoch: [ 3] [30932/61934] time: 31.96s (9839s total) loss: 0.777
I1207 07:05:13.049088 140435988830016 train.py:160] Epoch: [ 3] [31032/61934] time: 31.66s (9870s total) loss: 0.527
I1207 07:05:44.843093 140435988830016 train.py:160] Epoch: [ 3] [31132/61934] time: 31.79s (9902s total) loss: 1.032
I1207 07:06:16.675559 140435988830016 train.py:160] Epoch: [ 3] [31232/61934] time: 31.83s (9934s total) loss: 0.660
I1207 07:06:48.480616 140435988830016 train.py:160] Epoch: [ 3] [31332/61934] time: 31.81s (9966s total) loss: 0.782
I1207 07:07:20.455747 140435988830016 train.py:160] Epoch: [ 3] [31432/61934] time: 31.98s (9998s total) loss: 0.728
I1207 07:07:52.261741 140435988830016 train.py:160] Epoch: [ 3] [31532/61934] time: 31.81s (10030s total) loss: 0.689
I1207 07:08:23.990525 140435988830016 train.py:160] Epoch: [ 3] [31632/61934] time: 31.73s (10061s total) loss: 0.663
I1207 07:08:55.641344 140435988830016 train.py:160] Epoch: [ 3] [31732/61934] time: 31.65s (10093s total) loss: 0.637
I1207 07:09:27.500895 140435988830016 train.py:160] Epoch: [ 3] [31832/61934] time: 31.86s (10125s total) loss: 0.556
I1207 07:09:59.282570 140435988830016 train.py:160] Epoch: [ 3] [31932/61934] time: 31.78s (10157s total) loss: 0.922
I1207 07:10:31.290636 140435988830016 train.py:160] Epoch: [ 3] [32032/61934] time: 32.01s (10189s total) loss: 0.639
I1207 07:11:03.220324 140435988830016 train.py:160] Epoch: [ 3] [32132/61934] time: 31.93s (10221s total) loss: 0.610
I1207 07:11:35.063969 140435988830016 train.py:160] Epoch: [ 3] [32232/61934] time: 31.84s (10253s total) loss: 0.603
I1207 07:12:06.947530 140435988830016 train.py:160] Epoch: [ 3] [32332/61934] time: 31.88s (10284s total) loss: 0.642
I1207 07:12:38.716189 140435988830016 train.py:160] Epoch: [ 3] [32432/61934] time: 31.77s (10316s total) loss: 0.722
I1207 07:13:10.634154 140435988830016 train.py:160] Epoch: [ 3] [32532/61934] time: 31.92s (10348s total) loss: 0.422
I1207 07:13:42.591806 140435988830016 train.py:160] Epoch: [ 3] [32632/61934] time: 31.96s (10380s total) loss: 0.552
I1207 07:14:14.539584 140435988830016 train.py:160] Epoch: [ 3] [32732/61934] time: 31.95s (10412s total) loss: 0.615
I1207 07:14:46.299192 140435988830016 train.py:160] Epoch: [ 3] [32832/61934] time: 31.76s (10444s total) loss: 0.673
I1207 07:15:18.187669 140435988830016 train.py:160] Epoch: [ 3] [32932/61934] time: 31.89s (10476s total) loss: 0.453
I1207 07:15:49.920337 140435988830016 train.py:160] Epoch: [ 3] [33032/61934] time: 31.73s (10507s total) loss: 0.838
I1207 07:16:21.789487 140435988830016 train.py:160] Epoch: [ 3] [33132/61934] time: 31.87s (10539s total) loss: 0.538
I1207 07:16:53.645094 140435988830016 train.py:160] Epoch: [ 3] [33232/61934] time: 31.86s (10571s total) loss: 0.482
I1207 07:17:25.599055 140435988830016 train.py:160] Epoch: [ 3] [33332/61934] time: 31.95s (10603s total) loss: 0.801
I1207 07:17:57.384210 140435988830016 train.py:160] Epoch: [ 3] [33432/61934] time: 31.79s (10635s total) loss: 1.258
I1207 07:18:29.307289 140435988830016 train.py:160] Epoch: [ 3] [33532/61934] time: 31.92s (10667s total) loss: 0.660
I1207 07:19:01.115908 140435988830016 train.py:160] Epoch: [ 3] [33632/61934] time: 31.81s (10699s total) loss: 0.729
I1207 07:19:32.879881 140435988830016 train.py:160] Epoch: [ 3] [33732/61934] time: 31.76s (10730s total) loss: 0.640
I1207 07:20:04.624205 140435988830016 train.py:160] Epoch: [ 3] [33832/61934] time: 31.74s (10762s total) loss: 0.690
I1207 07:20:36.407257 140435988830016 train.py:160] Epoch: [ 3] [33932/61934] time: 31.78s (10794s total) loss: 0.642
I1207 07:21:08.254310 140435988830016 train.py:160] Epoch: [ 3] [34032/61934] time: 31.85s (10826s total) loss: 0.881
I1207 07:21:40.098259 140435988830016 train.py:160] Epoch: [ 3] [34132/61934] time: 31.84s (10858s total) loss: 0.575
I1207 07:22:12.145801 140435988830016 train.py:160] Epoch: [ 3] [34232/61934] time: 32.05s (10890s total) loss: 0.479
I1207 07:22:44.016850 140435988830016 train.py:160] Epoch: [ 3] [34332/61934] time: 31.87s (10921s total) loss: 0.525
I1207 07:23:15.776746 140435988830016 train.py:160] Epoch: [ 3] [34432/61934] time: 31.76s (10953s total) loss: 0.617
I1207 07:23:47.315336 140435988830016 train.py:160] Epoch: [ 3] [34532/61934] time: 31.54s (10985s total) loss: 0.609
I1207 07:24:18.852095 140435988830016 train.py:160] Epoch: [ 3] [34632/61934] time: 31.54s (11016s total) loss: 0.907
I1207 07:24:50.540059 140435988830016 train.py:160] Epoch: [ 3] [34732/61934] time: 31.69s (11048s total) loss: 0.579
I1207 07:25:22.211954 140435988830016 train.py:160] Epoch: [ 3] [34832/61934] time: 31.67s (11080s total) loss: 0.977
I1207 07:25:53.733074 140435988830016 train.py:160] Epoch: [ 3] [34932/61934] time: 31.52s (11111s total) loss: 0.613
I1207 07:26:25.328328 140435988830016 train.py:160] Epoch: [ 3] [35032/61934] time: 31.60s (11143s total) loss: 0.433
I1207 07:26:56.905695 140435988830016 train.py:160] Epoch: [ 3] [35132/61934] time: 31.58s (11174s total) loss: 0.708
I1207 07:27:28.526042 140435988830016 train.py:160] Epoch: [ 3] [35232/61934] time: 31.62s (11206s total) loss: 0.926
I1207 07:28:00.151734 140435988830016 train.py:160] Epoch: [ 3] [35332/61934] time: 31.63s (11238s total) loss: 0.578
I1207 07:28:31.765241 140435988830016 train.py:160] Epoch: [ 3] [35432/61934] time: 31.61s (11269s total) loss: 0.615
I1207 07:29:03.370368 140435988830016 train.py:160] Epoch: [ 3] [35532/61934] time: 31.61s (11301s total) loss: 0.870
I1207 07:29:34.943044 140435988830016 train.py:160] Epoch: [ 3] [35632/61934] time: 31.57s (11332s total) loss: 0.675
I1207 07:30:06.522953 140435988830016 train.py:160] Epoch: [ 3] [35732/61934] time: 31.58s (11364s total) loss: 0.754
I1207 07:30:38.113684 140435988830016 train.py:160] Epoch: [ 3] [35832/61934] time: 31.59s (11396s total) loss: 0.665
I1207 07:31:09.993529 140435988830016 train.py:160] Epoch: [ 3] [35932/61934] time: 31.88s (11427s total) loss: 0.597
I1207 07:31:41.567137 140435988830016 train.py:160] Epoch: [ 3] [36032/61934] time: 31.57s (11459s total) loss: 0.925
I1207 07:32:13.143393 140435988830016 train.py:160] Epoch: [ 3] [36132/61934] time: 31.58s (11491s total) loss: 0.483
I1207 07:32:44.690556 140435988830016 train.py:160] Epoch: [ 3] [36232/61934] time: 31.55s (11522s total) loss: 0.991
I1207 07:33:16.318437 140435988830016 train.py:160] Epoch: [ 3] [36332/61934] time: 31.63s (11554s total) loss: 0.649
I1207 07:33:47.852884 140435988830016 train.py:160] Epoch: [ 3] [36432/61934] time: 31.53s (11585s total) loss: 0.634
I1207 07:34:19.464506 140435988830016 train.py:160] Epoch: [ 3] [36532/61934] time: 31.61s (11617s total) loss: 0.534
I1207 07:34:51.093064 140435988830016 train.py:160] Epoch: [ 3] [36632/61934] time: 31.63s (11649s total) loss: 0.484
I1207 07:35:22.774938 140435988830016 train.py:160] Epoch: [ 3] [36732/61934] time: 31.68s (11680s total) loss: 1.054
I1207 07:35:54.281458 140435988830016 train.py:160] Epoch: [ 3] [36832/61934] time: 31.51s (11712s total) loss: 0.556
I1207 07:36:25.916590 140435988830016 train.py:160] Epoch: [ 3] [36932/61934] time: 31.64s (11743s total) loss: 0.583
I1207 07:36:57.493868 140435988830016 train.py:160] Epoch: [ 3] [37032/61934] time: 31.58s (11775s total) loss: 0.721
I1207 07:37:29.086291 140435988830016 train.py:160] Epoch: [ 3] [37132/61934] time: 31.59s (11807s total) loss: 0.595
I1207 07:38:00.610428 140435988830016 train.py:160] Epoch: [ 3] [37232/61934] time: 31.52s (11838s total) loss: 0.880
I1207 07:38:32.223105 140435988830016 train.py:160] Epoch: [ 3] [37332/61934] time: 31.61s (11870s total) loss: 0.986
I1207 07:39:03.819507 140435988830016 train.py:160] Epoch: [ 3] [37432/61934] time: 31.60s (11901s total) loss: 0.622
I1207 07:39:35.413425 140435988830016 train.py:160] Epoch: [ 3] [37532/61934] time: 31.59s (11933s total) loss: 0.533
I1207 07:40:06.941765 140435988830016 train.py:160] Epoch: [ 3] [37632/61934] time: 31.53s (11964s total) loss: 0.920
I1207 07:40:38.522573 140435988830016 train.py:160] Epoch: [ 3] [37732/61934] time: 31.58s (11996s total) loss: 0.712
I1207 07:41:10.052389 140435988830016 train.py:160] Epoch: [ 3] [37832/61934] time: 31.53s (12027s total) loss: 0.730
I1207 07:41:41.572893 140435988830016 train.py:160] Epoch: [ 3] [37932/61934] time: 31.52s (12059s total) loss: 0.645
I1207 07:42:13.232168 140435988830016 train.py:160] Epoch: [ 3] [38032/61934] time: 31.66s (12091s total) loss: 0.547
I1207 07:42:44.867401 140435988830016 train.py:160] Epoch: [ 3] [38132/61934] time: 31.64s (12122s total) loss: 0.443
I1207 07:43:16.387598 140435988830016 train.py:160] Epoch: [ 3] [38232/61934] time: 31.52s (12154s total) loss: 0.557
I1207 07:43:47.999284 140435988830016 train.py:160] Epoch: [ 3] [38332/61934] time: 31.61s (12185s total) loss: 0.548
I1207 07:44:19.659386 140435988830016 train.py:160] Epoch: [ 3] [38432/61934] time: 31.66s (12217s total) loss: 0.659
I1207 07:44:51.468788 140435988830016 train.py:160] Epoch: [ 3] [38532/61934] time: 31.81s (12249s total) loss: 0.636
I1207 07:45:23.084937 140435988830016 train.py:160] Epoch: [ 3] [38632/61934] time: 31.62s (12281s total) loss: 0.728
I1207 07:45:54.706473 140435988830016 train.py:160] Epoch: [ 3] [38732/61934] time: 31.62s (12312s total) loss: 0.638
I1207 07:46:26.290436 140435988830016 train.py:160] Epoch: [ 3] [38832/61934] time: 31.58s (12344s total) loss: 0.703
I1207 07:46:57.918740 140435988830016 train.py:160] Epoch: [ 3] [38932/61934] time: 31.63s (12375s total) loss: 0.498
I1207 07:47:29.443003 140435988830016 train.py:160] Epoch: [ 3] [39032/61934] time: 31.52s (12407s total) loss: 0.555
I1207 07:48:00.977519 140435988830016 train.py:160] Epoch: [ 3] [39132/61934] time: 31.53s (12438s total) loss: 0.943
I1207 07:48:32.607791 140435988830016 train.py:160] Epoch: [ 3] [39232/61934] time: 31.63s (12470s total) loss: 0.532
I1207 07:49:04.279926 140435988830016 train.py:160] Epoch: [ 3] [39332/61934] time: 31.67s (12502s total) loss: 0.504
I1207 07:49:35.857515 140435988830016 train.py:160] Epoch: [ 3] [39432/61934] time: 31.58s (12533s total) loss: 0.565
I1207 07:50:07.449980 140435988830016 train.py:160] Epoch: [ 3] [39532/61934] time: 31.59s (12565s total) loss: 0.640
I1207 07:50:39.050285 140435988830016 train.py:160] Epoch: [ 3] [39632/61934] time: 31.60s (12596s total) loss: 0.696
I1207 07:51:10.583872 140435988830016 train.py:160] Epoch: [ 3] [39732/61934] time: 31.53s (12628s total) loss: 0.705
I1207 07:51:42.112901 140435988830016 train.py:160] Epoch: [ 3] [39832/61934] time: 31.53s (12660s total) loss: 0.665
I1207 07:52:13.671542 140435988830016 train.py:160] Epoch: [ 3] [39932/61934] time: 31.56s (12691s total) loss: 0.783
I1207 07:52:45.253825 140435988830016 train.py:160] Epoch: [ 3] [40032/61934] time: 31.58s (12723s total) loss: 0.744
I1207 07:53:16.882858 140435988830016 train.py:160] Epoch: [ 3] [40132/61934] time: 31.63s (12754s total) loss: 0.597
I1207 07:53:48.418636 140435988830016 train.py:160] Epoch: [ 3] [40232/61934] time: 31.54s (12786s total) loss: 0.745
I1207 07:54:20.010844 140435988830016 train.py:160] Epoch: [ 3] [40332/61934] time: 31.59s (12817s total) loss: 0.571
I1207 07:54:51.562702 140435988830016 train.py:160] Epoch: [ 3] [40432/61934] time: 31.55s (12849s total) loss: 0.478
I1207 07:55:23.171746 140435988830016 train.py:160] Epoch: [ 3] [40532/61934] time: 31.61s (12881s total) loss: 0.707
I1207 07:55:54.882858 140435988830016 train.py:160] Epoch: [ 3] [40632/61934] time: 31.71s (12912s total) loss: 0.608
I1207 07:56:26.475247 140435988830016 train.py:160] Epoch: [ 3] [40732/61934] time: 31.59s (12944s total) loss: 0.689
I1207 07:56:58.132542 140435988830016 train.py:160] Epoch: [ 3] [40832/61934] time: 31.66s (12976s total) loss: 0.692
I1207 07:57:29.751497 140435988830016 train.py:160] Epoch: [ 3] [40932/61934] time: 31.62s (13007s total) loss: 0.441
I1207 07:58:01.443407 140435988830016 train.py:160] Epoch: [ 3] [41032/61934] time: 31.69s (13039s total) loss: 0.576
I1207 07:58:33.028367 140435988830016 train.py:160] Epoch: [ 3] [41132/61934] time: 31.59s (13070s total) loss: 0.682
I1207 07:59:04.621160 140435988830016 train.py:160] Epoch: [ 3] [41232/61934] time: 31.59s (13102s total) loss: 0.886
I1207 07:59:36.252156 140435988830016 train.py:160] Epoch: [ 3] [41332/61934] time: 31.63s (13134s total) loss: 0.550
I1207 08:00:07.910767 140435988830016 train.py:160] Epoch: [ 3] [41432/61934] time: 31.66s (13165s total) loss: 0.681
I1207 08:00:39.581261 140435988830016 train.py:160] Epoch: [ 3] [41532/61934] time: 31.67s (13197s total) loss: 0.550
I1207 08:01:11.234190 140435988830016 train.py:160] Epoch: [ 3] [41632/61934] time: 31.65s (13229s total) loss: 0.686
I1207 08:01:42.806386 140435988830016 train.py:160] Epoch: [ 3] [41732/61934] time: 31.57s (13260s total) loss: 0.766
I1207 08:02:14.468786 140435988830016 train.py:160] Epoch: [ 3] [41832/61934] time: 31.66s (13292s total) loss: 0.666
I1207 08:02:46.288301 140435988830016 train.py:160] Epoch: [ 3] [41932/61934] time: 31.82s (13324s total) loss: 1.003
I1207 08:03:17.935065 140435988830016 train.py:160] Epoch: [ 3] [42032/61934] time: 31.65s (13355s total) loss: 1.032
I1207 08:03:49.637710 140435988830016 train.py:160] Epoch: [ 3] [42132/61934] time: 31.70s (13387s total) loss: 0.789
I1207 08:04:21.303328 140435988830016 train.py:160] Epoch: [ 3] [42232/61934] time: 31.67s (13419s total) loss: 0.494
I1207 08:04:53.009132 140435988830016 train.py:160] Epoch: [ 3] [42332/61934] time: 31.71s (13450s total) loss: 0.484
I1207 08:05:24.607883 140435988830016 train.py:160] Epoch: [ 3] [42432/61934] time: 31.60s (13482s total) loss: 0.585
I1207 08:05:56.216252 140435988830016 train.py:160] Epoch: [ 3] [42532/61934] time: 31.61s (13514s total) loss: 0.791
I1207 08:06:27.777299 140435988830016 train.py:160] Epoch: [ 3] [42632/61934] time: 31.56s (13545s total) loss: 0.537
I1207 08:06:59.442904 140435988830016 train.py:160] Epoch: [ 3] [42732/61934] time: 31.67s (13577s total) loss: 0.588
I1207 08:07:31.116656 140435988830016 train.py:160] Epoch: [ 3] [42832/61934] time: 31.67s (13609s total) loss: 0.683
I1207 08:08:02.765852 140435988830016 train.py:160] Epoch: [ 3] [42932/61934] time: 31.65s (13640s total) loss: 0.647
I1207 08:08:34.327039 140435988830016 train.py:160] Epoch: [ 3] [43032/61934] time: 31.56s (13672s total) loss: 0.546
I1207 08:09:05.907864 140435988830016 train.py:160] Epoch: [ 3] [43132/61934] time: 31.58s (13703s total) loss: 0.384
I1207 08:09:37.672324 140435988830016 train.py:160] Epoch: [ 3] [43232/61934] time: 31.76s (13735s total) loss: 0.747
I1207 08:10:09.186891 140435988830016 train.py:160] Epoch: [ 3] [43332/61934] time: 31.51s (13767s total) loss: 0.829
I1207 08:10:40.723142 140435988830016 train.py:160] Epoch: [ 3] [43432/61934] time: 31.54s (13798s total) loss: 0.803
I1207 08:11:12.363199 140435988830016 train.py:160] Epoch: [ 3] [43532/61934] time: 31.64s (13830s total) loss: 0.607
I1207 08:11:43.956608 140435988830016 train.py:160] Epoch: [ 3] [43632/61934] time: 31.59s (13861s total) loss: 0.572
I1207 08:12:15.679921 140435988830016 train.py:160] Epoch: [ 3] [43732/61934] time: 31.72s (13893s total) loss: 0.621
I1207 08:12:47.294029 140435988830016 train.py:160] Epoch: [ 3] [43832/61934] time: 31.61s (13925s total) loss: 0.594
I1207 08:13:18.979997 140435988830016 train.py:160] Epoch: [ 3] [43932/61934] time: 31.69s (13956s total) loss: 0.840
I1207 08:13:50.649386 140435988830016 train.py:160] Epoch: [ 3] [44032/61934] time: 31.67s (13988s total) loss: 0.547
I1207 08:14:22.206073 140435988830016 train.py:160] Epoch: [ 3] [44132/61934] time: 31.56s (14020s total) loss: 0.795
I1207 08:14:53.900417 140435988830016 train.py:160] Epoch: [ 3] [44232/61934] time: 31.69s (14051s total) loss: 0.516
I1207 08:15:25.550724 140435988830016 train.py:160] Epoch: [ 3] [44332/61934] time: 31.65s (14083s total) loss: 0.600
I1207 08:15:57.149861 140435988830016 train.py:160] Epoch: [ 3] [44432/61934] time: 31.60s (14115s total) loss: 0.912
I1207 08:16:28.711257 140435988830016 train.py:160] Epoch: [ 3] [44532/61934] time: 31.56s (14146s total) loss: 0.505
I1207 08:17:00.384718 140435988830016 train.py:160] Epoch: [ 3] [44632/61934] time: 31.67s (14178s total) loss: 0.634
I1207 08:17:32.010413 140435988830016 train.py:160] Epoch: [ 3] [44732/61934] time: 31.63s (14209s total) loss: 0.546
I1207 08:18:03.641999 140435988830016 train.py:160] Epoch: [ 3] [44832/61934] time: 31.63s (14241s total) loss: 0.717
I1207 08:18:35.279021 140435988830016 train.py:160] Epoch: [ 3] [44932/61934] time: 31.64s (14273s total) loss: 0.467
I1207 08:19:06.837373 140435988830016 train.py:160] Epoch: [ 3] [45032/61934] time: 31.56s (14304s total) loss: 0.656
I1207 08:19:38.464589 140435988830016 train.py:160] Epoch: [ 3] [45132/61934] time: 31.63s (14336s total) loss: 0.681
I1207 08:20:10.052828 140435988830016 train.py:160] Epoch: [ 3] [45232/61934] time: 31.59s (14367s total) loss: 0.931
I1207 08:20:41.760865 140435988830016 train.py:160] Epoch: [ 3] [45332/61934] time: 31.71s (14399s total) loss: 0.504
I1207 08:21:13.353884 140435988830016 train.py:160] Epoch: [ 3] [45432/61934] time: 31.59s (14431s total) loss: 0.615
I1207 08:21:44.957813 140435988830016 train.py:160] Epoch: [ 3] [45532/61934] time: 31.60s (14462s total) loss: 0.726
I1207 08:22:16.578819 140435988830016 train.py:160] Epoch: [ 3] [45632/61934] time: 31.62s (14494s total) loss: 0.693
I1207 08:22:48.120049 140435988830016 train.py:160] Epoch: [ 3] [45732/61934] time: 31.54s (14526s total) loss: 0.662
I1207 08:23:19.736745 140435988830016 train.py:160] Epoch: [ 3] [45832/61934] time: 31.62s (14557s total) loss: 0.589
I1207 08:23:51.377918 140435988830016 train.py:160] Epoch: [ 3] [45932/61934] time: 31.64s (14589s total) loss: 0.572
I1207 08:24:23.028249 140435988830016 train.py:160] Epoch: [ 3] [46032/61934] time: 31.65s (14620s total) loss: 0.475
I1207 08:24:54.637398 140435988830016 train.py:160] Epoch: [ 3] [46132/61934] time: 31.61s (14652s total) loss: 0.648
I1207 08:25:26.236378 140435988830016 train.py:160] Epoch: [ 3] [46232/61934] time: 31.60s (14684s total) loss: 0.743
I1207 08:25:57.858016 140435988830016 train.py:160] Epoch: [ 3] [46332/61934] time: 31.62s (14715s total) loss: 0.629
I1207 08:26:29.486620 140435988830016 train.py:160] Epoch: [ 3] [46432/61934] time: 31.63s (14747s total) loss: 0.738
I1207 08:27:01.139225 140435988830016 train.py:160] Epoch: [ 3] [46532/61934] time: 31.65s (14779s total) loss: 1.025
I1207 08:27:32.857213 140435988830016 train.py:160] Epoch: [ 3] [46632/61934] time: 31.72s (14810s total) loss: 0.616
I1207 08:28:04.514448 140435988830016 train.py:160] Epoch: [ 3] [46732/61934] time: 31.66s (14842s total) loss: 0.839
I1207 08:28:36.218005 140435988830016 train.py:160] Epoch: [ 3] [46832/61934] time: 31.70s (14874s total) loss: 1.192
I1207 08:29:07.788141 140435988830016 train.py:160] Epoch: [ 3] [46932/61934] time: 31.57s (14905s total) loss: 0.680
I1207 08:29:39.385818 140435988830016 train.py:160] Epoch: [ 3] [47032/61934] time: 31.60s (14937s total) loss: 0.581
I1207 08:30:10.954533 140435988830016 train.py:160] Epoch: [ 3] [47132/61934] time: 31.57s (14968s total) loss: 0.452
I1207 08:30:42.607915 140435988830016 train.py:160] Epoch: [ 3] [47232/61934] time: 31.65s (15000s total) loss: 1.135
I1207 08:31:14.242080 140435988830016 train.py:160] Epoch: [ 3] [47332/61934] time: 31.63s (15032s total) loss: 0.602
I1207 08:31:45.920382 140435988830016 train.py:160] Epoch: [ 3] [47432/61934] time: 31.68s (15063s total) loss: 0.729
I1207 08:32:17.599974 140435988830016 train.py:160] Epoch: [ 3] [47532/61934] time: 31.68s (15095s total) loss: 0.758
I1207 08:32:49.259759 140435988830016 train.py:160] Epoch: [ 3] [47632/61934] time: 31.66s (15127s total) loss: 0.729
I1207 08:33:20.946173 140435988830016 train.py:160] Epoch: [ 3] [47732/61934] time: 31.69s (15158s total) loss: 0.479
I1207 08:33:52.558935 140435988830016 train.py:160] Epoch: [ 3] [47832/61934] time: 31.61s (15190s total) loss: 0.594
I1207 08:34:24.195863 140435988830016 train.py:160] Epoch: [ 3] [47932/61934] time: 31.64s (15222s total) loss: 0.821
I1207 08:34:56.026016 140435988830016 train.py:160] Epoch: [ 3] [48032/61934] time: 31.83s (15253s total) loss: 0.715
I1207 08:35:27.528928 140435988830016 train.py:160] Epoch: [ 3] [48132/61934] time: 31.50s (15285s total) loss: 0.662
I1207 08:35:59.094626 140435988830016 train.py:160] Epoch: [ 3] [48232/61934] time: 31.57s (15317s total) loss: 0.793
I1207 08:36:30.691409 140435988830016 train.py:160] Epoch: [ 3] [48332/61934] time: 31.60s (15348s total) loss: 0.695
I1207 08:37:02.372547 140435988830016 train.py:160] Epoch: [ 3] [48432/61934] time: 31.68s (15380s total) loss: 0.756
I1207 08:37:33.969430 140435988830016 train.py:160] Epoch: [ 3] [48532/61934] time: 31.60s (15411s total) loss: 0.835
I1207 08:38:05.626014 140435988830016 train.py:160] Epoch: [ 3] [48632/61934] time: 31.66s (15443s total) loss: 0.701
I1207 08:38:37.265009 140435988830016 train.py:160] Epoch: [ 3] [48732/61934] time: 31.64s (15475s total) loss: 0.533
I1207 08:39:08.941817 140435988830016 train.py:160] Epoch: [ 3] [48832/61934] time: 31.68s (15506s total) loss: 0.650
I1207 08:39:40.551855 140435988830016 train.py:160] Epoch: [ 3] [48932/61934] time: 31.61s (15538s total) loss: 0.720
I1207 08:40:12.177555 140435988830016 train.py:160] Epoch: [ 3] [49032/61934] time: 31.63s (15570s total) loss: 1.124
I1207 08:40:43.716102 140435988830016 train.py:160] Epoch: [ 3] [49132/61934] time: 31.54s (15601s total) loss: 0.835
I1207 08:41:15.519379 140435988830016 train.py:160] Epoch: [ 3] [49232/61934] time: 31.80s (15633s total) loss: 0.515
I1207 08:41:47.134224 140435988830016 train.py:160] Epoch: [ 3] [49332/61934] time: 31.61s (15665s total) loss: 1.168
I1207 08:42:18.780800 140435988830016 train.py:160] Epoch: [ 3] [49432/61934] time: 31.65s (15696s total) loss: 0.604
I1207 08:42:50.411933 140435988830016 train.py:160] Epoch: [ 3] [49532/61934] time: 31.63s (15728s total) loss: 0.814
I1207 08:43:21.992111 140435988830016 train.py:160] Epoch: [ 3] [49632/61934] time: 31.58s (15759s total) loss: 0.644
I1207 08:43:53.467066 140435988830016 train.py:160] Epoch: [ 3] [49732/61934] time: 31.47s (15791s total) loss: 0.596
I1207 08:44:25.097009 140435988830016 train.py:160] Epoch: [ 3] [49832/61934] time: 31.63s (15823s total) loss: 0.762
I1207 08:44:56.761065 140435988830016 train.py:160] Epoch: [ 3] [49932/61934] time: 31.66s (15854s total) loss: 0.814
I1207 08:45:28.457600 140435988830016 train.py:160] Epoch: [ 3] [50032/61934] time: 31.70s (15886s total) loss: 0.535
I1207 08:46:00.044218 140435988830016 train.py:160] Epoch: [ 3] [50132/61934] time: 31.59s (15917s total) loss: 0.968
I1207 08:46:31.689888 140435988830016 train.py:160] Epoch: [ 3] [50232/61934] time: 31.65s (15949s total) loss: 0.756
I1207 08:47:03.338890 140435988830016 train.py:160] Epoch: [ 3] [50332/61934] time: 31.65s (15981s total) loss: 0.671
I1207 08:47:34.836983 140435988830016 train.py:160] Epoch: [ 3] [50432/61934] time: 31.50s (16012s total) loss: 1.588
I1207 08:48:06.419210 140435988830016 train.py:160] Epoch: [ 3] [50532/61934] time: 31.58s (16044s total) loss: 1.058
I1207 08:48:38.088537 140435988830016 train.py:160] Epoch: [ 3] [50632/61934] time: 31.67s (16076s total) loss: 0.635
I1207 08:49:09.725610 140435988830016 train.py:160] Epoch: [ 3] [50732/61934] time: 31.64s (16107s total) loss: 0.553
I1207 08:49:41.357265 140435988830016 train.py:160] Epoch: [ 3] [50832/61934] time: 31.63s (16139s total) loss: 0.481
I1207 08:50:12.963156 140435988830016 train.py:160] Epoch: [ 3] [50932/61934] time: 31.61s (16170s total) loss: 0.760
I1207 08:50:44.505456 140435988830016 train.py:160] Epoch: [ 3] [51032/61934] time: 31.54s (16202s total) loss: 0.623
I1207 08:51:16.102706 140435988830016 train.py:160] Epoch: [ 3] [51132/61934] time: 31.60s (16234s total) loss: 0.973
I1207 08:51:47.767374 140435988830016 train.py:160] Epoch: [ 3] [51232/61934] time: 31.66s (16265s total) loss: 0.476
I1207 08:52:19.458095 140435988830016 train.py:160] Epoch: [ 3] [51332/61934] time: 31.69s (16297s total) loss: 0.676
I1207 08:52:51.078803 140435988830016 train.py:160] Epoch: [ 3] [51432/61934] time: 31.62s (16329s total) loss: 0.555
I1207 08:53:22.816878 140435988830016 train.py:160] Epoch: [ 3] [51532/61934] time: 31.74s (16360s total) loss: 0.563
I1207 08:53:54.338812 140435988830016 train.py:160] Epoch: [ 3] [51632/61934] time: 31.52s (16392s total) loss: 0.984
I1207 08:54:25.936094 140435988830016 train.py:160] Epoch: [ 3] [51732/61934] time: 31.60s (16423s total) loss: 0.696
I1207 08:54:57.516370 140435988830016 train.py:160] Epoch: [ 3] [51832/61934] time: 31.58s (16455s total) loss: 0.629
I1207 08:55:29.160505 140435988830016 train.py:160] Epoch: [ 3] [51932/61934] time: 31.64s (16487s total) loss: 0.465
I1207 08:56:00.824444 140435988830016 train.py:160] Epoch: [ 3] [52032/61934] time: 31.66s (16518s total) loss: 0.698
I1207 08:56:32.431293 140435988830016 train.py:160] Epoch: [ 3] [52132/61934] time: 31.61s (16550s total) loss: 0.878
I1207 08:57:04.103721 140435988830016 train.py:160] Epoch: [ 3] [52232/61934] time: 31.67s (16582s total) loss: 0.835
I1207 08:57:35.685274 140435988830016 train.py:160] Epoch: [ 3] [52332/61934] time: 31.58s (16613s total) loss: 0.558
I1207 08:58:07.348020 140435988830016 train.py:160] Epoch: [ 3] [52432/61934] time: 31.66s (16645s total) loss: 0.511
I1207 08:58:38.960896 140435988830016 train.py:160] Epoch: [ 3] [52532/61934] time: 31.61s (16676s total) loss: 0.677
I1207 08:59:10.567042 140435988830016 train.py:160] Epoch: [ 3] [52632/61934] time: 31.61s (16708s total) loss: 1.166
I1207 08:59:42.268405 140435988830016 train.py:160] Epoch: [ 3] [52732/61934] time: 31.70s (16740s total) loss: 0.409
I1207 09:00:13.844076 140435988830016 train.py:160] Epoch: [ 3] [52832/61934] time: 31.58s (16771s total) loss: 0.506
I1207 09:00:45.491238 140435988830016 train.py:160] Epoch: [ 3] [52932/61934] time: 31.65s (16803s total) loss: 0.583
I1207 09:01:17.227360 140435988830016 train.py:160] Epoch: [ 3] [53032/61934] time: 31.74s (16835s total) loss: 0.682
I1207 09:01:48.925824 140435988830016 train.py:160] Epoch: [ 3] [53132/61934] time: 31.70s (16866s total) loss: 0.609
I1207 09:02:20.565874 140435988830016 train.py:160] Epoch: [ 3] [53232/61934] time: 31.64s (16898s total) loss: 0.594
I1207 09:02:52.214078 140435988830016 train.py:160] Epoch: [ 3] [53332/61934] time: 31.65s (16930s total) loss: 0.625
I1207 09:03:23.896150 140435988830016 train.py:160] Epoch: [ 3] [53432/61934] time: 31.68s (16961s total) loss: 0.608
I1207 09:03:55.467262 140435988830016 train.py:160] Epoch: [ 3] [53532/61934] time: 31.57s (16993s total) loss: 0.635
I1207 09:04:27.053984 140435988830016 train.py:160] Epoch: [ 3] [53632/61934] time: 31.59s (17024s total) loss: 0.627
I1207 09:04:58.624447 140435988830016 train.py:160] Epoch: [ 3] [53732/61934] time: 31.57s (17056s total) loss: 0.712
I1207 09:05:30.212225 140435988830016 train.py:160] Epoch: [ 3] [53832/61934] time: 31.59s (17088s total) loss: 0.786
I1207 09:06:01.873848 140435988830016 train.py:160] Epoch: [ 3] [53932/61934] time: 31.66s (17119s total) loss: 0.707
I1207 09:06:33.353607 140435988830016 train.py:160] Epoch: [ 3] [54032/61934] time: 31.48s (17151s total) loss: 0.682
I1207 09:07:05.018328 140435988830016 train.py:160] Epoch: [ 3] [54132/61934] time: 31.66s (17182s total) loss: 1.007
I1207 09:07:36.564278 140435988830016 train.py:160] Epoch: [ 3] [54232/61934] time: 31.55s (17214s total) loss: 0.712
I1207 09:08:08.094565 140435988830016 train.py:160] Epoch: [ 3] [54332/61934] time: 31.53s (17246s total) loss: 0.784
I1207 09:08:39.740622 140435988830016 train.py:160] Epoch: [ 3] [54432/61934] time: 31.65s (17277s total) loss: 0.629
I1207 09:09:11.434808 140435988830016 train.py:160] Epoch: [ 3] [54532/61934] time: 31.69s (17309s total) loss: 0.589
I1207 09:09:43.013648 140435988830016 train.py:160] Epoch: [ 3] [54632/61934] time: 31.58s (17340s total) loss: 0.690
I1207 09:10:14.621171 140435988830016 train.py:160] Epoch: [ 3] [54732/61934] time: 31.61s (17372s total) loss: 0.749
I1207 09:10:46.227668 140435988830016 train.py:160] Epoch: [ 3] [54832/61934] time: 31.61s (17404s total) loss: 0.602
I1207 09:11:17.839471 140435988830016 train.py:160] Epoch: [ 3] [54932/61934] time: 31.61s (17435s total) loss: 0.581
I1207 09:11:49.432497 140435988830016 train.py:160] Epoch: [ 3] [55032/61934] time: 31.59s (17467s total) loss: 1.092
I1207 09:12:21.086016 140435988830016 train.py:160] Epoch: [ 3] [55132/61934] time: 31.65s (17499s total) loss: 0.875
I1207 09:12:52.694586 140435988830016 train.py:160] Epoch: [ 3] [55232/61934] time: 31.61s (17530s total) loss: 0.866
I1207 09:13:24.291983 140435988830016 train.py:160] Epoch: [ 3] [55332/61934] time: 31.60s (17562s total) loss: 1.087
I1207 09:13:55.969427 140435988830016 train.py:160] Epoch: [ 3] [55432/61934] time: 31.68s (17593s total) loss: 0.816
I1207 09:14:27.600323 140435988830016 train.py:160] Epoch: [ 3] [55532/61934] time: 31.63s (17625s total) loss: 0.916
I1207 09:14:59.264184 140435988830016 train.py:160] Epoch: [ 3] [55632/61934] time: 31.66s (17657s total) loss: 0.674
I1207 09:15:30.896219 140435988830016 train.py:160] Epoch: [ 3] [55732/61934] time: 31.63s (17688s total) loss: 0.739
I1207 09:16:02.554577 140435988830016 train.py:160] Epoch: [ 3] [55832/61934] time: 31.66s (17720s total) loss: 0.543
I1207 09:16:34.230708 140435988830016 train.py:160] Epoch: [ 3] [55932/61934] time: 31.68s (17752s total) loss: 0.791
I1207 09:17:05.897622 140435988830016 train.py:160] Epoch: [ 3] [56032/61934] time: 31.67s (17783s total) loss: 0.924
I1207 09:17:37.553700 140435988830016 train.py:160] Epoch: [ 3] [56132/61934] time: 31.66s (17815s total) loss: 0.502
I1207 09:18:09.179439 140435988830016 train.py:160] Epoch: [ 3] [56232/61934] time: 31.63s (17847s total) loss: 0.649
I1207 09:18:40.740775 140435988830016 train.py:160] Epoch: [ 3] [56332/61934] time: 31.56s (17878s total) loss: 0.736
I1207 09:19:12.356031 140435988830016 train.py:160] Epoch: [ 3] [56432/61934] time: 31.62s (17910s total) loss: 0.533
I1207 09:19:44.125306 140435988830016 train.py:160] Epoch: [ 3] [56532/61934] time: 31.77s (17942s total) loss: 0.425
I1207 09:20:15.705274 140435988830016 train.py:160] Epoch: [ 3] [56632/61934] time: 31.58s (17973s total) loss: 0.605
I1207 09:20:47.260850 140435988830016 train.py:160] Epoch: [ 3] [56732/61934] time: 31.56s (18005s total) loss: 0.427
I1207 09:21:18.858265 140435988830016 train.py:160] Epoch: [ 3] [56832/61934] time: 31.60s (18036s total) loss: 0.964
I1207 09:21:50.452572 140435988830016 train.py:160] Epoch: [ 3] [56932/61934] time: 31.59s (18068s total) loss: 1.037
I1207 09:22:22.081032 140435988830016 train.py:160] Epoch: [ 3] [57032/61934] time: 31.63s (18100s total) loss: 0.687
I1207 09:22:53.648749 140435988830016 train.py:160] Epoch: [ 3] [57132/61934] time: 31.57s (18131s total) loss: 0.676
I1207 09:23:25.231675 140435988830016 train.py:160] Epoch: [ 3] [57232/61934] time: 31.58s (18163s total) loss: 0.647
I1207 09:23:56.839704 140435988830016 train.py:160] Epoch: [ 3] [57332/61934] time: 31.61s (18194s total) loss: 0.377
I1207 09:24:28.405179 140435988830016 train.py:160] Epoch: [ 3] [57432/61934] time: 31.57s (18226s total) loss: 0.617
I1207 09:24:59.980636 140435988830016 train.py:160] Epoch: [ 3] [57532/61934] time: 31.58s (18257s total) loss: 0.948
I1207 09:25:31.435881 140435988830016 train.py:160] Epoch: [ 3] [57632/61934] time: 31.46s (18289s total) loss: 0.427
I1207 09:26:03.006045 140435988830016 train.py:160] Epoch: [ 3] [57732/61934] time: 31.57s (18320s total) loss: 0.615
I1207 09:26:34.545627 140435988830016 train.py:160] Epoch: [ 3] [57832/61934] time: 31.54s (18352s total) loss: 0.678
I1207 09:27:06.127852 140435988830016 train.py:160] Epoch: [ 3] [57932/61934] time: 31.58s (18384s total) loss: 0.715
I1207 09:27:37.723234 140435988830016 train.py:160] Epoch: [ 3] [58032/61934] time: 31.60s (18415s total) loss: 0.637
I1207 09:28:09.377840 140435988830016 train.py:160] Epoch: [ 3] [58132/61934] time: 31.65s (18447s total) loss: 0.776
I1207 09:28:40.903377 140435988830016 train.py:160] Epoch: [ 3] [58232/61934] time: 31.53s (18478s total) loss: 0.844
I1207 09:29:12.532545 140435988830016 train.py:160] Epoch: [ 3] [58332/61934] time: 31.63s (18510s total) loss: 0.638
I1207 09:29:44.107811 140435988830016 train.py:160] Epoch: [ 3] [58432/61934] time: 31.58s (18542s total) loss: 0.594
I1207 09:30:15.724237 140435988830016 train.py:160] Epoch: [ 3] [58532/61934] time: 31.62s (18573s total) loss: 0.585
I1207 09:30:47.300553 140435988830016 train.py:160] Epoch: [ 3] [58632/61934] time: 31.58s (18605s total) loss: 0.601
I1207 09:31:18.954450 140435988830016 train.py:160] Epoch: [ 3] [58732/61934] time: 31.65s (18636s total) loss: 0.648
I1207 09:31:50.545690 140435988830016 train.py:160] Epoch: [ 3] [58832/61934] time: 31.59s (18668s total) loss: 0.692
I1207 09:32:22.302287 140435988830016 train.py:160] Epoch: [ 3] [58932/61934] time: 31.76s (18700s total) loss: 1.253
I1207 09:32:53.717733 140435988830016 train.py:160] Epoch: [ 3] [59032/61934] time: 31.42s (18731s total) loss: 0.736
I1207 09:33:25.295228 140435988830016 train.py:160] Epoch: [ 3] [59132/61934] time: 31.58s (18763s total) loss: 0.548
I1207 09:33:56.865894 140435988830016 train.py:160] Epoch: [ 3] [59232/61934] time: 31.57s (18794s total) loss: 0.770
I1207 09:34:28.514904 140435988830016 train.py:160] Epoch: [ 3] [59332/61934] time: 31.65s (18826s total) loss: 0.704
I1207 09:35:00.052173 140435988830016 train.py:160] Epoch: [ 3] [59432/61934] time: 31.54s (18857s total) loss: 0.534
I1207 09:35:31.677672 140435988830016 train.py:160] Epoch: [ 3] [59532/61934] time: 31.63s (18889s total) loss: 0.893
I1207 09:36:03.292138 140435988830016 train.py:160] Epoch: [ 3] [59632/61934] time: 31.61s (18921s total) loss: 0.609
I1207 09:36:34.917378 140435988830016 train.py:160] Epoch: [ 3] [59732/61934] time: 31.63s (18952s total) loss: 0.709
I1207 09:37:06.484932 140435988830016 train.py:160] Epoch: [ 3] [59832/61934] time: 31.57s (18984s total) loss: 0.657
I1207 09:37:38.012251 140435988830016 train.py:160] Epoch: [ 3] [59932/61934] time: 31.53s (19015s total) loss: 0.696
I1207 09:38:09.634956 140435988830016 train.py:160] Epoch: [ 3] [60032/61934] time: 31.62s (19047s total) loss: 0.604
I1207 09:38:41.115205 140435988830016 train.py:160] Epoch: [ 3] [60132/61934] time: 31.48s (19079s total) loss: 0.522
I1207 09:39:12.696738 140435988830016 train.py:160] Epoch: [ 3] [60232/61934] time: 31.58s (19110s total) loss: 0.616
I1207 09:39:44.226429 140435988830016 train.py:160] Epoch: [ 3] [60332/61934] time: 31.53s (19142s total) loss: 1.036
I1207 09:40:15.786370 140435988830016 train.py:160] Epoch: [ 3] [60432/61934] time: 31.56s (19173s total) loss: 0.638
I1207 09:40:47.330698 140435988830016 train.py:160] Epoch: [ 3] [60532/61934] time: 31.54s (19205s total) loss: 0.527
I1207 09:41:18.871577 140435988830016 train.py:160] Epoch: [ 3] [60632/61934] time: 31.54s (19236s total) loss: 0.617
I1207 09:41:50.439398 140435988830016 train.py:160] Epoch: [ 3] [60732/61934] time: 31.57s (19268s total) loss: 0.900
I1207 09:42:22.051279 140435988830016 train.py:160] Epoch: [ 3] [60832/61934] time: 31.61s (19299s total) loss: 0.588
I1207 09:42:53.633752 140435988830016 train.py:160] Epoch: [ 3] [60932/61934] time: 31.58s (19331s total) loss: 1.157
I1207 09:43:25.202562 140435988830016 train.py:160] Epoch: [ 3] [61032/61934] time: 31.57s (19363s total) loss: 0.523
I1207 09:43:56.769545 140435988830016 train.py:160] Epoch: [ 3] [61132/61934] time: 31.57s (19394s total) loss: 0.600
I1207 09:44:28.595000 140435988830016 train.py:160] Epoch: [ 3] [61232/61934] time: 31.83s (19426s total) loss: 0.732
I1207 09:45:00.107424 140435988830016 train.py:160] Epoch: [ 3] [61332/61934] time: 31.51s (19458s total) loss: 0.674
I1207 09:45:31.695175 140435988830016 train.py:160] Epoch: [ 3] [61432/61934] time: 31.59s (19489s total) loss: 0.767
I1207 09:46:03.291284 140435988830016 train.py:160] Epoch: [ 3] [61532/61934] time: 31.60s (19521s total) loss: 0.505
I1207 09:46:34.941261 140435988830016 train.py:160] Epoch: [ 3] [61632/61934] time: 31.65s (19552s total) loss: 0.708
I1207 09:47:06.526709 140435988830016 train.py:160] Epoch: [ 3] [61732/61934] time: 31.59s (19584s total) loss: 0.603
I1207 09:47:38.154739 140435988830016 train.py:160] Epoch: [ 3] [61832/61934] time: 31.63s (19616s total) loss: 0.623
I1207 09:48:09.867386 140435988830016 train.py:160] Epoch: [ 3] [61932/61934] time: 31.71s (19647s total) loss: 0.822
I1207 09:48:10.488110 140435988830016 train.py:163] [*] Saving checkpoint to /home/pachipala/vid2depth/checkpoints...
I1207 09:48:44.507916 140435988830016 train.py:160] Epoch: [ 4] [   98/61934] time: 34.64s (19682s total) loss: 0.652
I1207 09:49:16.135552 140435988830016 train.py:160] Epoch: [ 4] [  198/61934] time: 31.63s (19714s total) loss: 0.712
I1207 09:49:47.635354 140435988830016 train.py:160] Epoch: [ 4] [  298/61934] time: 31.50s (19745s total) loss: 0.694
I1207 09:50:19.166851 140435988830016 train.py:160] Epoch: [ 4] [  398/61934] time: 31.53s (19777s total) loss: 0.819
I1207 09:50:50.689782 140435988830016 train.py:160] Epoch: [ 4] [  498/61934] time: 31.52s (19808s total) loss: 0.642
I1207 09:51:22.252587 140435988830016 train.py:160] Epoch: [ 4] [  598/61934] time: 31.56s (19840s total) loss: 0.632
I1207 09:51:53.781456 140435988830016 train.py:160] Epoch: [ 4] [  698/61934] time: 31.53s (19871s total) loss: 0.851
I1207 09:52:25.385533 140435988830016 train.py:160] Epoch: [ 4] [  798/61934] time: 31.60s (19903s total) loss: 0.516
I1207 09:52:56.934706 140435988830016 train.py:160] Epoch: [ 4] [  898/61934] time: 31.55s (19934s total) loss: 0.664
I1207 09:53:28.527414 140435988830016 train.py:160] Epoch: [ 4] [  998/61934] time: 31.59s (19966s total) loss: 0.693
I1207 09:54:00.128727 140435988830016 train.py:160] Epoch: [ 4] [ 1098/61934] time: 31.60s (19998s total) loss: 0.665
I1207 09:54:31.805171 140435988830016 train.py:160] Epoch: [ 4] [ 1198/61934] time: 31.68s (20029s total) loss: 0.548
I1207 09:55:03.482842 140435988830016 train.py:160] Epoch: [ 4] [ 1298/61934] time: 31.68s (20061s total) loss: 0.755
I1207 09:55:35.130589 140435988830016 train.py:160] Epoch: [ 4] [ 1398/61934] time: 31.65s (20093s total) loss: 0.625
I1207 09:56:06.872868 140435988830016 train.py:160] Epoch: [ 4] [ 1498/61934] time: 31.74s (20124s total) loss: 0.459
I1207 09:56:38.461377 140435988830016 train.py:160] Epoch: [ 4] [ 1598/61934] time: 31.59s (20156s total) loss: 0.942
I1207 09:57:10.088334 140435988830016 train.py:160] Epoch: [ 4] [ 1698/61934] time: 31.63s (20188s total) loss: 0.512
I1207 09:57:41.951704 140435988830016 train.py:160] Epoch: [ 4] [ 1798/61934] time: 31.86s (20219s total) loss: 0.449
I1207 09:58:13.539695 140435988830016 train.py:160] Epoch: [ 4] [ 1898/61934] time: 31.59s (20251s total) loss: 0.541
I1207 09:58:45.127264 140435988830016 train.py:160] Epoch: [ 4] [ 1998/61934] time: 31.59s (20283s total) loss: 1.174
I1207 09:59:16.717776 140435988830016 train.py:160] Epoch: [ 4] [ 2098/61934] time: 31.59s (20314s total) loss: 0.626
I1207 09:59:48.346260 140435988830016 train.py:160] Epoch: [ 4] [ 2198/61934] time: 31.63s (20346s total) loss: 0.421
I1207 10:00:19.962466 140435988830016 train.py:160] Epoch: [ 4] [ 2298/61934] time: 31.62s (20377s total) loss: 0.501
I1207 10:00:51.689559 140435988830016 train.py:160] Epoch: [ 4] [ 2398/61934] time: 31.73s (20409s total) loss: 0.811
I1207 10:01:23.332185 140435988830016 train.py:160] Epoch: [ 4] [ 2498/61934] time: 31.64s (20441s total) loss: 0.659
I1207 10:01:54.922605 140435988830016 train.py:160] Epoch: [ 4] [ 2598/61934] time: 31.59s (20472s total) loss: 0.911
I1207 10:02:26.580706 140435988830016 train.py:160] Epoch: [ 4] [ 2698/61934] time: 31.66s (20504s total) loss: 0.733
I1207 10:02:58.206374 140435988830016 train.py:160] Epoch: [ 4] [ 2798/61934] time: 31.63s (20536s total) loss: 0.883
I1207 10:03:29.844780 140435988830016 train.py:160] Epoch: [ 4] [ 2898/61934] time: 31.64s (20567s total) loss: 0.991
I1207 10:04:01.417424 140435988830016 train.py:160] Epoch: [ 4] [ 2998/61934] time: 31.57s (20599s total) loss: 0.684
I1207 10:04:32.962890 140435988830016 train.py:160] Epoch: [ 4] [ 3098/61934] time: 31.55s (20630s total) loss: 0.793
I1207 10:05:04.564680 140435988830016 train.py:160] Epoch: [ 4] [ 3198/61934] time: 31.60s (20662s total) loss: 0.753
I1207 10:05:36.212705 140435988830016 train.py:160] Epoch: [ 4] [ 3298/61934] time: 31.65s (20694s total) loss: 0.738
I1207 10:06:07.749254 140435988830016 train.py:160] Epoch: [ 4] [ 3398/61934] time: 31.54s (20725s total) loss: 0.770
I1207 10:06:39.360344 140435988830016 train.py:160] Epoch: [ 4] [ 3498/61934] time: 31.61s (20757s total) loss: 0.735
I1207 10:07:11.053933 140435988830016 train.py:160] Epoch: [ 4] [ 3598/61934] time: 31.69s (20788s total) loss: 0.618
I1207 10:07:42.627808 140435988830016 train.py:160] Epoch: [ 4] [ 3698/61934] time: 31.57s (20820s total) loss: 0.603
I1207 10:08:14.232900 140435988830016 train.py:160] Epoch: [ 4] [ 3798/61934] time: 31.61s (20852s total) loss: 0.717
I1207 10:08:45.863186 140435988830016 train.py:160] Epoch: [ 4] [ 3898/61934] time: 31.63s (20883s total) loss: 0.690
I1207 10:09:17.572547 140435988830016 train.py:160] Epoch: [ 4] [ 3998/61934] time: 31.71s (20915s total) loss: 0.865
I1207 10:09:49.570174 140435988830016 train.py:160] Epoch: [ 4] [ 4098/61934] time: 32.00s (20947s total) loss: 0.622
I1207 10:10:21.174806 140435988830016 train.py:160] Epoch: [ 4] [ 4198/61934] time: 31.60s (20979s total) loss: 0.613
I1207 10:10:52.868639 140435988830016 train.py:160] Epoch: [ 4] [ 4298/61934] time: 31.69s (21010s total) loss: 1.023
I1207 10:11:24.581567 140435988830016 train.py:160] Epoch: [ 4] [ 4398/61934] time: 31.71s (21042s total) loss: 0.518
I1207 10:11:56.239869 140435988830016 train.py:160] Epoch: [ 4] [ 4498/61934] time: 31.66s (21074s total) loss: 0.783
I1207 10:12:27.899155 140435988830016 train.py:160] Epoch: [ 4] [ 4598/61934] time: 31.66s (21105s total) loss: 0.733
I1207 10:12:59.555773 140435988830016 train.py:160] Epoch: [ 4] [ 4698/61934] time: 31.66s (21137s total) loss: 0.710
I1207 10:13:31.280548 140435988830016 train.py:160] Epoch: [ 4] [ 4798/61934] time: 31.72s (21169s total) loss: 0.973
I1207 10:14:03.022230 140435988830016 train.py:160] Epoch: [ 4] [ 4898/61934] time: 31.74s (21200s total) loss: 0.641
I1207 10:14:34.616093 140435988830016 train.py:160] Epoch: [ 4] [ 4998/61934] time: 31.59s (21232s total) loss: 0.754
I1207 10:15:06.238720 140435988830016 train.py:160] Epoch: [ 4] [ 5098/61934] time: 31.62s (21264s total) loss: 0.712
I1207 10:15:38.045960 140435988830016 train.py:160] Epoch: [ 4] [ 5198/61934] time: 31.81s (21295s total) loss: 0.647
I1207 10:16:09.586157 140435988830016 train.py:160] Epoch: [ 4] [ 5298/61934] time: 31.54s (21327s total) loss: 0.640
I1207 10:16:41.220393 140435988830016 train.py:160] Epoch: [ 4] [ 5398/61934] time: 31.63s (21359s total) loss: 0.585
I1207 10:17:12.797990 140435988830016 train.py:160] Epoch: [ 4] [ 5498/61934] time: 31.58s (21390s total) loss: 0.653
I1207 10:17:44.372654 140435988830016 train.py:160] Epoch: [ 4] [ 5598/61934] time: 31.57s (21422s total) loss: 0.523
I1207 10:18:16.019397 140435988830016 train.py:160] Epoch: [ 4] [ 5698/61934] time: 31.65s (21453s total) loss: 0.705
I1207 10:18:47.590757 140435988830016 train.py:160] Epoch: [ 4] [ 5798/61934] time: 31.57s (21485s total) loss: 0.775
I1207 10:19:19.394003 140435988830016 train.py:160] Epoch: [ 4] [ 5898/61934] time: 31.80s (21517s total) loss: 0.662
I1207 10:19:51.037827 140435988830016 train.py:160] Epoch: [ 4] [ 5998/61934] time: 31.64s (21548s total) loss: 0.755
I1207 10:20:22.701517 140435988830016 train.py:160] Epoch: [ 4] [ 6098/61934] time: 31.66s (21580s total) loss: 0.812
I1207 10:20:54.347888 140435988830016 train.py:160] Epoch: [ 4] [ 6198/61934] time: 31.65s (21612s total) loss: 0.476
I1207 10:21:25.920301 140435988830016 train.py:160] Epoch: [ 4] [ 6298/61934] time: 31.57s (21643s total) loss: 0.875
I1207 10:21:57.525575 140435988830016 train.py:160] Epoch: [ 4] [ 6398/61934] time: 31.61s (21675s total) loss: 0.481
I1207 10:22:29.150154 140435988830016 train.py:160] Epoch: [ 4] [ 6498/61934] time: 31.62s (21707s total) loss: 0.370
I1207 10:23:00.910418 140435988830016 train.py:160] Epoch: [ 4] [ 6598/61934] time: 31.76s (21738s total) loss: 0.804
I1207 10:23:32.522048 140435988830016 train.py:160] Epoch: [ 4] [ 6698/61934] time: 31.61s (21770s total) loss: 0.558
I1207 10:24:04.189170 140435988830016 train.py:160] Epoch: [ 4] [ 6798/61934] time: 31.67s (21802s total) loss: 0.745
I1207 10:24:35.796509 140435988830016 train.py:160] Epoch: [ 4] [ 6898/61934] time: 31.61s (21833s total) loss: 0.713
I1207 10:25:07.399643 140435988830016 train.py:160] Epoch: [ 4] [ 6998/61934] time: 31.60s (21865s total) loss: 0.643
I1207 10:25:38.988907 140435988830016 train.py:160] Epoch: [ 4] [ 7098/61934] time: 31.59s (21896s total) loss: 0.919
I1207 10:26:10.545399 140435988830016 train.py:160] Epoch: [ 4] [ 7198/61934] time: 31.56s (21928s total) loss: 0.684
I1207 10:26:42.255500 140435988830016 train.py:160] Epoch: [ 4] [ 7298/61934] time: 31.71s (21960s total) loss: 0.496
I1207 10:27:13.761138 140435988830016 train.py:160] Epoch: [ 4] [ 7398/61934] time: 31.51s (21991s total) loss: 0.559
I1207 10:27:45.432000 140435988830016 train.py:160] Epoch: [ 4] [ 7498/61934] time: 31.67s (22023s total) loss: 0.552
I1207 10:28:17.035100 140435988830016 train.py:160] Epoch: [ 4] [ 7598/61934] time: 31.60s (22054s total) loss: 0.871
I1207 10:28:48.625689 140435988830016 train.py:160] Epoch: [ 4] [ 7698/61934] time: 31.59s (22086s total) loss: 0.466
I1207 10:29:20.254101 140435988830016 train.py:160] Epoch: [ 4] [ 7798/61934] time: 31.63s (22118s total) loss: 0.598
I1207 10:29:51.806239 140435988830016 train.py:160] Epoch: [ 4] [ 7898/61934] time: 31.55s (22149s total) loss: 0.569
I1207 10:30:23.410784 140435988830016 train.py:160] Epoch: [ 4] [ 7998/61934] time: 31.60s (22181s total) loss: 0.615
I1207 10:30:55.032931 140435988830016 train.py:160] Epoch: [ 4] [ 8098/61934] time: 31.62s (22212s total) loss: 0.592
I1207 10:31:26.993563 140435988830016 train.py:160] Epoch: [ 4] [ 8198/61934] time: 31.96s (22244s total) loss: 0.539
I1207 10:31:58.575666 140435988830016 train.py:160] Epoch: [ 4] [ 8298/61934] time: 31.58s (22276s total) loss: 0.747
I1207 10:32:30.359473 140435988830016 train.py:160] Epoch: [ 4] [ 8398/61934] time: 31.78s (22308s total) loss: 0.578
I1207 10:33:01.750049 140435988830016 train.py:160] Epoch: [ 4] [ 8498/61934] time: 31.39s (22339s total) loss: 0.481
I1207 10:33:33.459532 140435988830016 train.py:160] Epoch: [ 4] [ 8598/61934] time: 31.71s (22371s total) loss: 0.648
I1207 10:34:05.091317 140435988830016 train.py:160] Epoch: [ 4] [ 8698/61934] time: 31.63s (22403s total) loss: 0.765
I1207 10:34:36.742830 140435988830016 train.py:160] Epoch: [ 4] [ 8798/61934] time: 31.65s (22434s total) loss: 0.886
I1207 10:35:08.454979 140435988830016 train.py:160] Epoch: [ 4] [ 8898/61934] time: 31.71s (22466s total) loss: 0.442
I1207 10:35:40.129248 140435988830016 train.py:160] Epoch: [ 4] [ 8998/61934] time: 31.67s (22498s total) loss: 0.592
I1207 10:36:11.795178 140435988830016 train.py:160] Epoch: [ 4] [ 9098/61934] time: 31.67s (22529s total) loss: 0.457
I1207 10:36:43.526934 140435988830016 train.py:160] Epoch: [ 4] [ 9198/61934] time: 31.73s (22561s total) loss: 0.916
I1207 10:37:15.145411 140435988830016 train.py:160] Epoch: [ 4] [ 9298/61934] time: 31.62s (22593s total) loss: 0.777
I1207 10:37:46.729895 140435988830016 train.py:160] Epoch: [ 4] [ 9398/61934] time: 31.58s (22624s total) loss: 0.562
I1207 10:38:18.399126 140435988830016 train.py:160] Epoch: [ 4] [ 9498/61934] time: 31.67s (22656s total) loss: 0.637
I1207 10:38:49.961210 140435988830016 train.py:160] Epoch: [ 4] [ 9598/61934] time: 31.56s (22687s total) loss: 0.808
I1207 10:39:21.543084 140435988830016 train.py:160] Epoch: [ 4] [ 9698/61934] time: 31.58s (22719s total) loss: 0.438
I1207 10:39:53.240646 140435988830016 train.py:160] Epoch: [ 4] [ 9798/61934] time: 31.70s (22751s total) loss: 0.585
I1207 10:40:24.907431 140435988830016 train.py:160] Epoch: [ 4] [ 9898/61934] time: 31.67s (22782s total) loss: 0.638
I1207 10:40:56.454138 140435988830016 train.py:160] Epoch: [ 4] [ 9998/61934] time: 31.55s (22814s total) loss: 0.839
I1207 10:41:28.151757 140435988830016 train.py:160] Epoch: [ 4] [10098/61934] time: 31.70s (22846s total) loss: 1.029
I1207 10:41:59.810810 140435988830016 train.py:160] Epoch: [ 4] [10198/61934] time: 31.66s (22877s total) loss: 0.729
I1207 10:42:31.493126 140435988830016 train.py:160] Epoch: [ 4] [10298/61934] time: 31.68s (22909s total) loss: 0.849
I1207 10:43:03.086402 140435988830016 train.py:160] Epoch: [ 4] [10398/61934] time: 31.59s (22941s total) loss: 0.854
I1207 10:43:34.701801 140435988830016 train.py:160] Epoch: [ 4] [10498/61934] time: 31.62s (22972s total) loss: 0.946
I1207 10:44:06.413243 140435988830016 train.py:160] Epoch: [ 4] [10598/61934] time: 31.71s (23004s total) loss: 0.819
I1207 10:44:38.104085 140435988830016 train.py:160] Epoch: [ 4] [10698/61934] time: 31.69s (23036s total) loss: 0.571
I1207 10:45:09.624841 140435988830016 train.py:160] Epoch: [ 4] [10798/61934] time: 31.52s (23067s total) loss: 0.967
I1207 10:45:41.243441 140435988830016 train.py:160] Epoch: [ 4] [10898/61934] time: 31.62s (23099s total) loss: 1.230
I1207 10:46:12.893325 140435988830016 train.py:160] Epoch: [ 4] [10998/61934] time: 31.65s (23130s total) loss: 0.522
I1207 10:46:44.526592 140435988830016 train.py:160] Epoch: [ 4] [11098/61934] time: 31.63s (23162s total) loss: 0.772
I1207 10:47:16.129797 140435988830016 train.py:160] Epoch: [ 4] [11198/61934] time: 31.60s (23194s total) loss: 0.977
I1207 10:47:47.701218 140435988830016 train.py:160] Epoch: [ 4] [11298/61934] time: 31.57s (23225s total) loss: 0.569
I1207 10:48:19.349453 140435988830016 train.py:160] Epoch: [ 4] [11398/61934] time: 31.65s (23257s total) loss: 1.194
I1207 10:48:50.989110 140435988830016 train.py:160] Epoch: [ 4] [11498/61934] time: 31.64s (23288s total) loss: 0.763
I1207 10:49:22.512379 140435988830016 train.py:160] Epoch: [ 4] [11598/61934] time: 31.52s (23320s total) loss: 0.543
I1207 10:49:54.115098 140435988830016 train.py:160] Epoch: [ 4] [11698/61934] time: 31.60s (23352s total) loss: 0.385
I1207 10:50:25.773612 140435988830016 train.py:160] Epoch: [ 4] [11798/61934] time: 31.66s (23383s total) loss: 0.602
I1207 10:50:57.357193 140435988830016 train.py:160] Epoch: [ 4] [11898/61934] time: 31.58s (23415s total) loss: 0.700
I1207 10:51:29.090350 140435988830016 train.py:160] Epoch: [ 4] [11998/61934] time: 31.73s (23447s total) loss: 0.527
I1207 10:52:00.965488 140435988830016 train.py:160] Epoch: [ 4] [12098/61934] time: 31.88s (23478s total) loss: 0.595
I1207 10:52:32.550435 140435988830016 train.py:160] Epoch: [ 4] [12198/61934] time: 31.58s (23510s total) loss: 0.732
I1207 10:53:04.079689 140435988830016 train.py:160] Epoch: [ 4] [12298/61934] time: 31.53s (23542s total) loss: 0.587
I1207 10:53:35.658941 140435988830016 train.py:160] Epoch: [ 4] [12398/61934] time: 31.58s (23573s total) loss: 0.625
I1207 10:54:07.316671 140435988830016 train.py:160] Epoch: [ 4] [12498/61934] time: 31.66s (23605s total) loss: 0.563
I1207 10:54:38.898021 140435988830016 train.py:160] Epoch: [ 4] [12598/61934] time: 31.58s (23636s total) loss: 0.493
I1207 10:55:10.537774 140435988830016 train.py:160] Epoch: [ 4] [12698/61934] time: 31.64s (23668s total) loss: 0.541
I1207 10:55:42.294114 140435988830016 train.py:160] Epoch: [ 4] [12798/61934] time: 31.76s (23700s total) loss: 0.501
I1207 10:56:14.170479 140435988830016 train.py:160] Epoch: [ 4] [12898/61934] time: 31.88s (23732s total) loss: 0.549
I1207 10:56:45.733041 140435988830016 train.py:160] Epoch: [ 4] [12998/61934] time: 31.56s (23763s total) loss: 0.819
I1207 10:57:17.251179 140435988830016 train.py:160] Epoch: [ 4] [13098/61934] time: 31.52s (23795s total) loss: 0.700
I1207 10:57:49.238390 140435988830016 train.py:160] Epoch: [ 4] [13198/61934] time: 31.99s (23827s total) loss: 0.558
I1207 10:58:20.823810 140435988830016 train.py:160] Epoch: [ 4] [13298/61934] time: 31.59s (23858s total) loss: 0.690
I1207 10:58:52.489647 140435988830016 train.py:160] Epoch: [ 4] [13398/61934] time: 31.67s (23890s total) loss: 0.658
I1207 10:59:24.065454 140435988830016 train.py:160] Epoch: [ 4] [13498/61934] time: 31.58s (23922s total) loss: 0.748
I1207 10:59:55.694753 140435988830016 train.py:160] Epoch: [ 4] [13598/61934] time: 31.63s (23953s total) loss: 0.871
I1207 11:00:27.319700 140435988830016 train.py:160] Epoch: [ 4] [13698/61934] time: 31.62s (23985s total) loss: 0.761
I1207 11:00:58.942806 140435988830016 train.py:160] Epoch: [ 4] [13798/61934] time: 31.62s (24016s total) loss: 0.596
I1207 11:01:30.684470 140435988830016 train.py:160] Epoch: [ 4] [13898/61934] time: 31.74s (24048s total) loss: 0.582
I1207 11:02:02.239877 140435988830016 train.py:160] Epoch: [ 4] [13998/61934] time: 31.56s (24080s total) loss: 0.597
I1207 11:02:33.863271 140435988830016 train.py:160] Epoch: [ 4] [14098/61934] time: 31.62s (24111s total) loss: 0.769
I1207 11:03:05.454493 140435988830016 train.py:160] Epoch: [ 4] [14198/61934] time: 31.59s (24143s total) loss: 0.592
